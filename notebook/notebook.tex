
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{BWF Badminton}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{bwf-badminton-tournaments}{%
\section{BWF Badminton tournaments}\label{bwf-badminton-tournaments}}

\hypertarget{bayesian-data-analysis-project-09-dec-2018}{%
\subparagraph{Bayesian Data Analysis Project,
09-Dec-2018}\label{bayesian-data-analysis-project-09-dec-2018}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \hypertarget{introduction}{%
\subsection{1 Introduction}\label{introduction}}

\textbf{Goal}: analyze the distribution of outcomes in a badminton
tournament.

\textbf{Approach}: apply Bayesian data analysis on historical data of
badminton tournaments. The estimand of interest is the probability of a
certain outcome. The modelling of a match outcome will be explained more
in section 2.

\textbf{Implementation}: * Start with some naive assumption of the
estimand, in order to choose the model later * Collect and preprocess
data * Decide on prior choices and models * Do stan analysis on each
models * Model comparision (using PSIS-LOO) * Do posterior predictive
comparision between models * Conclusion, possible improvements

\hypertarget{analysis-problem}{%
\subsection{2 Analysis problem}\label{analysis-problem}}

\hypertarget{discretizing-the-problem}{%
\subsubsection{2.1 Discretizing the
problem}\label{discretizing-the-problem}}

In one tournament, there are 8 seed players and some unranked players.
To discretize the ranking spread, we chose 12th as the rank for all
unranked players. The spread is calculated as follows:

\textbf{Spread (from 1st player perspective) = Rank(2nd player) -
Rank(1st player)}

E.g.

\begin{itemize}
\tightlist
\item
  Spread(from 1st rank player to 8th rank player) = 8 - 1 = 7
\item
  Spread(from 2nd rank player to unrank player) = 12 - 2 = 10
\item
  Spread(from unrank player to 3rd rank player) = 3 - 12 = -9
\end{itemize}

The discrete space for ranking spread is then
\textbf{{[}-11,-10,-9,\ldots{},9,10,11{]}}

A match (which has at most 3 games) has 6 possible outcomes: 1. Lose
Lose -\textgreater{} Lose 2. Lose Win Lose -\textgreater{} Lose 3. Win
Lose Lose -\textgreater{} Lose 4. Lose Win Win -\textgreater{} Win 5.
Win Lose Win -\textgreater{} Win 6. Win Win -\textgreater{} Win

To discretize this parameter, we map the outcome of a match to
\textbf{{[}1,2,3,4,5,6{]}} in terms of win degree (i.e.~win degree 1 is
the worst, and win degree 6 is the best).

    For the match below, ranking spread is 11, win degree is 4

\hypertarget{modeling-the-problem}{%
\subsubsection{2.2 Modeling the problem}\label{modeling-the-problem}}

Unless stated otherwise, all information in the data are from 1st player
perspective\\
An observation of a match includes 2 pieces of information: * ranking
spread * win degree

To formulate the observations as a one dimensional space collection, we
need to reduce the matrix 23x6 (23 different spreads, 6 different win
degrees) of all possible raw observations. The intuition of the
reduction is as follows: * With the same ranking spread, higher win
degree correlates to higher value (see arrow A in image below) * With
the same win degree, lower ranking spread correlates to higher value
(see arrow B in image below) * Step between value is 1

With the given constraint, we will have \textbf{28 possible values of
observation from {[}1,28{]}}. The mapping is as follow (columns are win
degrees and rows are ranking spreads)

\hypertarget{analysing-the-problem}{%
\subsubsection{2.3 Analysing the problem}\label{analysing-the-problem}}

The problem analysis explores the distribution of the observations,
especially concentrating on the predictive distribution of the new
tournament. Furthermore, we will try to analyze the affect of the
different models and prior choices.

    \hypertarget{dataset-and-data-model}{%
\subsection{3 Dataset and data model}\label{dataset-and-data-model}}

The dataset is collected from Badminton World Federation (BWF)
tournament database using Scrapy crawler. After collecting, the data is
preprocessed as stated in the previous section. In the end, the format
of data is similar to the factory data assignments. A peek of the data:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{show\PYZus{}first\PYZus{}rows\PYZus{}of\PYZus{}data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:}          Tournament 1  Tournament 2  Tournament 3  Tournament 4  Tournament 5
        Match 1           6.0          17.0          16.0           6.0           1.0
        Match 2          15.0          15.0          17.0          13.0          17.0
        Match 3          16.0           7.0           4.0          17.0           5.0
        Match 4          15.0          13.0          17.0          17.0          13.0
        Match 5          19.0          20.0          20.0          15.0          17.0
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{show\PYZus{}summary\PYZus{}of\PYZus{}data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}        Tournament 1  Tournament 2  Tournament 3  Tournament 4  Tournament 5
        count     67.000000     67.000000     67.000000     67.000000     67.000000
        mean      13.776119     14.388060     13.746269     14.880597     14.164179
        std        5.746727      5.635266      5.329572      5.878885      5.703792
        min        4.000000      3.000000      4.000000      3.000000      1.000000
        25\%        9.000000     10.000000      8.000000     10.000000     10.000000
        50\%       15.000000     15.000000     15.000000     16.000000     16.000000
        75\%       17.000000     18.000000     17.000000     17.000000     17.000000
        max       25.000000     27.000000     26.000000     27.000000     27.000000
\end{Verbatim}
            
    \hypertarget{prior-choices}{%
\subsection{4 Prior choices}\label{prior-choices}}

We decided to use two different priors: * \textbf{Inverse gamma} is
chosen on variance because it is the conjugate prior to normal
likelihood and it has a closed form solution for the outcome of the
posterior * \textbf{Uniform} is chosen as weak prior to observe how
sensitive is outcome in regards the prior and the data input

    \hypertarget{model}{%
\subsection{5 Model}\label{model}}

In normal distribution where \(\mu\) is known and \(\sigma^2\) is
unknown, the marginal posterior distribution \(p(\sigma^2|y)\) can be
computed as described below. The posterior distribution is computed
using two different priors, whereas the first is an uniformative
(uniform) and the second an informative (inverse gamma) prior.

\textbf{Priors:}

Uniform prior

\begin{equation*}
p(\sigma^2) \propto Uniform(0, \infty)
\end{equation*}

Inverse gamma prior

\begin{equation*}  
p(\sigma^2) \propto (\sigma^2)^{-(a+1)}e^{-\beta/\sigma^2} \propto Inv-Gamma(\alpha, \beta) \\
\end{equation*}

where \(\alpha=1\) and \(\beta=1\) are the shape and scale parameters.
Our prior assumption is that variance will be relatively small but we
are not sure how small it is, and our guess is around {[}1,2{]}. The pdf
of inverse gamma with \(\alpha=1\) and \(\beta=1\) is a good fit for our
assumption

\textbf{Likelihood:} \begin{equation*}
p(y|\mu,\sigma^2) \propto \prod_{i=1}^{N} p(y_i | \mu, \sigma^2) \propto N(y | \mu, \sigma^2) 
\end{equation*}

where \(\mu\) is known.

\textbf{Posterior:}

\begin{equation*}
p(\sigma^2 | y) \propto p(\sigma^2)p(y|\mu, \sigma^2)
\end{equation*}

Since one of the objective is to predict the distribution of a new
tournament, we will use pooled and hierarchical model. The separate
model is excluded because it handles the tournaments uniquely without
having any common parameters which could be used to predict the new
tournament.

In the pooled model the mean and the variance is computed from the
combined data of all the tournaments and there is no distinction between
different tournaments. This means that also the new tournament will have
similar distibution as the predictive distribution of the tournaments.

In the hierarchical model each tournament is handled separately having
own mean and common standard deviation. Furthermore, all the means are
controlled by common hyperparameters (\(\mu_0\) and \(\sigma^2_0\))
which means that the means are drawn from the common distribution
described by these hyperparameters. The result of the new tournament can
be predicted using the common hyperparameters: first draw the mean from
the common distribution and use it to sample the predictive
distribution.

Then based on the prior choices, we have 4 different models: * pooled
with uniform prior * pooled with inverse gamma prior for variance *
hierarchical with uniform prior * hierarchical with inverse gamma prior
for variance

    \hypertarget{stan-analysis-of-the-models}{%
\subsection{6 Stan analysis of the
models}\label{stan-analysis-of-the-models}}

For each model, we will show the Stan model and convergence diagnostic.

The Stan model is fitted using Stan's default parameters (4 chains, 1000
warmup iterations, 1000 sampling iteration, ending up to 4000 samples
and 10 as maximum tree depth). In addition, to avoid false positive
conclusion about divergences, the \emph{adapt\_delta} value is set to
0.9. This means that the fitting uses larger target acceptance
probability and therefore all the divergences can be seen. If the
resulting value is still 0 after this, we can verify that there are no
divergences. If not, the divergences could be further analyzed by
increasing \emph{adapt\_delta}.

Besides divergences, the convergence diagnostic includes a short
discussion about \(\hat R\) and n\_eff. Generally, if the \(\hat R\)
values of the parameters are close to 1 and below 1.1, the fit has been
good. The low \(\hat R\) values combined with high effective sample size
(n\_eff) per transition informs that the Markov chains were mixed well.
Note that discussion about depth tree and energy Bayesian fraction of
missing information (E-BFMI) is left out because their results were same
for all the models (depth tree 0 and E-BFMI did not give any
information).

\hypertarget{pooled-model-with-uniform-prior}{%
\subsubsection{6.1 Pooled model with uniform
prior}\label{pooled-model-with-uniform-prior}}

\hypertarget{stan-model}{%
\paragraph{Stan model}\label{stan-model}}

The stan code of the model:

\begin{verbatim}
data {
  int<lower=0> N;       // Number of observations
  vector[N] y;           // N observations for J tournaments
}
parameters {
  real mu;              // Common mean
  real<lower=0> sigma;  // Common std
}
model {
  y ~ normal(mu, sigma);// Model for fitting data using tournament specific mu and common std
}
generated quantities {
  vector[N] log_lik;
  real ypred;
  
  ypred = normal_rng(mu, sigma);                  //Prediction of tournament
  for (n in 1:N)
    log_lik[n] = normal_lpdf(y[n] | mu, sigma);   //Log-likelihood
}
\end{verbatim}

\hypertarget{convergence-diagnostic}{%
\paragraph{Convergence diagnostic}\label{convergence-diagnostic}}

After compiling the model and fitting the combined data of the
tournaments, the diagnostic of the fit was examined:

\begin{longtable}[]{@{}ll@{}}
\toprule
Diagnostic & Result\tabularnewline
\midrule
\endhead
All \(\hat R\) values close to 1 & OK\tabularnewline
Low \(\hat R\) values combined with high effective sample size (n\_eff)
& OK\tabularnewline
Divergences is 0 & OK\tabularnewline
\bottomrule
\end{longtable}

All the results for pooled uniform prior model fitting are good. The
full fit can be found in the \emph{Attachment 1} and a shorter summary
is shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} Fit pooled uniform model}
        \PY{n}{pool\PYZus{}uni\PYZus{}df}\PY{p}{,} \PY{n}{pool\PYZus{}uni\PYZus{}fit} \PY{o}{=} \PY{n}{compute\PYZus{}model}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stan\PYZus{}code/pool\PYZus{}uniform\PYZus{}prior.stan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{pooled\PYZus{}data\PYZus{}model}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Print summary of the fit}
        \PY{n}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{pool\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using cached StanModel

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:}                  mean      se\_mean         sd     2.5\%      25\%      50\%  \textbackslash{}
        mu            14.1935   0.00603298   0.314179  13.5613  13.9842  14.2001   
        sigma         5.66282   0.00441324   0.224035  5.24378  5.50642  5.65253   
        log\_lik[0]   -3.70522   0.00177279   0.091105 -3.89356 -3.76527 -3.70164   
        log\_lik[1]   -2.66381  0.000781838  0.0394576  -2.7439 -2.68967 -2.66273   
        log\_lik[2]   -2.70475  0.000794411  0.0395853 -2.78604 -2.73049 -2.70434   
        {\ldots}               {\ldots}          {\ldots}        {\ldots}      {\ldots}      {\ldots}      {\ldots}   
        log\_lik[332] -2.70475  0.000794411  0.0395853 -2.78604 -2.73049 -2.70434   
        log\_lik[333] -2.81336  0.000768998  0.0414903 -2.89455 -2.84142 -2.81289   
        log\_lik[334] -3.46419     0.001425  0.0745643 -3.61728 -3.51306 -3.46244   
        ypred         14.2868    0.0901683    5.70274  3.42566  10.3648  14.2842   
        lp\_\_         -746.025    0.0248809    1.00668 -748.748 -746.425 -745.714   
        
                          75\%    97.5\% n\_eff      Rhat  
        mu             14.409  14.8204  2712   1.00109  
        sigma         5.80839  6.12739  2577   1.00018  
        log\_lik[0]   -3.64204 -3.53086  2641   1.00078  
        log\_lik[1]   -2.63632 -2.58826  2547   1.00023  
        log\_lik[2]   -2.67761 -2.62968  2483   1.00032  
        {\ldots}               {\ldots}      {\ldots}   {\ldots}       {\ldots}  
        log\_lik[332] -2.67761 -2.62968  2483   1.00032  
        log\_lik[333] -2.78428 -2.73293  2911   1.00091  
        log\_lik[334] -3.41316 -3.32091  2738   1.00092  
        ypred         18.1957  25.5974  4000  0.999995  
        lp\_\_         -745.295 -745.018  1637  0.999565  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Print additional checking of the fit}
        \PY{n}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{pool\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{pool\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Maximum value of the Rhat: 
1.0012218111524749

Divergences:
0.0 of 4000 iterations ended with a divergence (0.0\%)


    \end{Verbatim}

    \hypertarget{pooled-model-with-inverse-gamma-prior}{%
\subsubsection{6.2 Pooled model with inverse gamma
prior}\label{pooled-model-with-inverse-gamma-prior}}

\hypertarget{stan-model}{%
\paragraph{Stan model}\label{stan-model}}

The stan code of the model:

\begin{verbatim}
data {
  int<lower=0> N;        // Number of observations
  vector[N] y;            // N observations for J tournaments
  real<lower=0.1> alpha;  //Shape
  real<lower=0.1> beta;  //Scale
}
parameters {
  real mu;               // Common mean
  real<lower=0> sigmaSq; // Common var
}
transformed parameters {
  real<lower=0> sigma;
  sigma <- sqrt(sigmaSq);
}
model {
  sigmaSq ~ inv_gamma(alpha,beta);  // Prior
  y ~ normal(mu, sigma);            // Fitting of the model
}
generated quantities {
  vector[N] log_lik;
  real ypred;
  
  ypred = normal_rng(mu, sigma);    // Prediction of tournament
  for (n in 1:N)
    log_lik[n] = normal_lpdf(y[n] | mu, sigma); //Log-likelihood
}
\end{verbatim}

\hypertarget{convergence-diagnostic}{%
\paragraph{Convergence diagnostic}\label{convergence-diagnostic}}

The same procedure is followed here (as in the previous section) and
similar results were obtained:

\begin{longtable}[]{@{}ll@{}}
\toprule
Diagnostic & Result\tabularnewline
\midrule
\endhead
All \(\hat R\) values close to 1 & OK\tabularnewline
Low \(\hat R\) values combined with high effective sample size (n\_eff)
& OK\tabularnewline
Divergences is 0 & OK\tabularnewline
\bottomrule
\end{longtable}

All the results for pooled inverse gamma prior model fitting are good.
The full fit can be found in the \emph{Attachment 2} and a shorter
summary is shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} Fit pooled inverse gamma model}
        \PY{n}{pool\PYZus{}inv\PYZus{}df}\PY{p}{,} \PY{n}{pool\PYZus{}inv\PYZus{}fit} \PY{o}{=} \PY{n}{compute\PYZus{}model}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stan\PYZus{}code/pool\PYZus{}inverse\PYZus{}gamma\PYZus{}prior.stan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{pooled\PYZus{}data\PYZus{}model}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Print summary of the fit}
        \PY{n}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{pool\PYZus{}inv\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using cached StanModel

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:}                  mean      se\_mean         sd     2.5\%      25\%      50\%  \textbackslash{}
        mu            14.1912   0.00659562   0.311324  13.5848  13.9808  14.1944   
        sigmaSq        31.819    0.0465451    2.42705  27.4953  30.0994   31.688   
        sigma         5.63676    0.0040921    0.21424   5.2436  5.48629  5.62921   
        log\_lik[0]   -3.70983   0.00189007  0.0933245 -3.89964 -3.77044  -3.7058   
        log\_lik[1]   -2.65936  0.000735954  0.0384743 -2.73647 -2.68499 -2.65882   
        {\ldots}               {\ldots}          {\ldots}        {\ldots}      {\ldots}      {\ldots}      {\ldots}   
        log\_lik[332] -2.70068  0.000759725   0.039352 -2.78049 -2.72698 -2.70021   
        log\_lik[333] -2.81015  0.000869736  0.0394174 -2.88917 -2.83559 -2.80985   
        log\_lik[334] -3.46668    0.0015697  0.0761101 -3.62117 -3.51465 -3.46372   
        ypred         14.2633      0.08992    5.61407  3.23815  10.4847   14.328   
        lp\_\_         -751.202    0.0262385    1.01486 -753.917 -751.573 -750.898   
        
                          75\%    97.5\% n\_eff      Rhat  
        mu            14.3957  14.8102  2228   1.00237  
        sigmaSq       33.3725  36.8217  2719   1.00037  
        sigma         5.77689  6.06809  2741   1.00037  
        log\_lik[0]   -3.64535 -3.53664  2438   1.00087  
        log\_lik[1]   -2.63316 -2.58596  2733  0.999909  
        {\ldots}               {\ldots}      {\ldots}   {\ldots}       {\ldots}  
        log\_lik[332] -2.67379 -2.62523  2683  0.999668  
        log\_lik[333] -2.78294  -2.7354  2054   1.00321  
        log\_lik[334] -3.41446  -3.3255  2351   1.00139  
        ypred         18.0029   25.224  3898  0.999202  
        lp\_\_         -750.491 -750.235  1496   1.00201  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} Print additional checking of the fit}
        \PY{n}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{pool\PYZus{}inv\PYZus{}fit}\PY{p}{,} \PY{n}{pool\PYZus{}inv\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Maximum value of the Rhat: 
1.00330613987631

Divergences:
0.0 of 4000 iterations ended with a divergence (0.0\%)


    \end{Verbatim}

    \hypertarget{hierarchical-model-with-uniform-prior}{%
\subsubsection{6.3 Hierarchical model with uniform
prior}\label{hierarchical-model-with-uniform-prior}}

\hypertarget{unsuccessful-fitting}{%
\subsubsection{6.3.1 Unsuccessful fitting}\label{unsuccessful-fitting}}

\hypertarget{stan-model}{%
\paragraph{Stan model}\label{stan-model}}

The stan code of the model:

\begin{verbatim}
data {
  int<lower=0> N;  // Number of observations
  int<lower=0> J;  // Number of tournaments
  matrix[N,J] y;  // N observations for J tournaments
}
parameters {
  real mu0;             // Common mu for each J tournament's mu
  real<lower=0> sigma0; // Common std for each J tournament's mu
  real<lower=0> sigma; // Common std between tournaments
  real mu_tilde[J];    // Tournament specific mu
}
model {
  for (j in 1:J)
    mu[j] ~ normal(mu0, sigma0);       // Model for computing tournament specific mu from common mu0 and sigma0
  for (j in 1:J)
    y[:,j] ~ normal(mu[j], sigma);  // Model for fitting data using tournament specific mu and common std
}
generated quantities {
  matrix[N,J] log_lik;    
  real ypred[J];
  real mu_new;
  real ypred_new;
  
  for (j in 1:J)
     ypred[j] = normal_rng(mu[j], sigma);   // Predictive distibutions of all the tournaments
  mu_new = normal_rng(mu0, sigma0);       // Next posterior distribution from commonly learned mu0 and sigma0
  ypred_new = normal_rng(mu_new, sigma);    // Next predictive distibutions of new tournament
  
  for (j in 1:J)
     for (n in 1:N)
        log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma); //Log-likelihood
}
\end{verbatim}

    \hypertarget{convergence-diagnostic-attempt-1}{%
\paragraph{Convergence diagnostic attempt
1}\label{convergence-diagnostic-attempt-1}}

The same procedure is followed here (as in the previous section) with
minor change. The data used for fitting is a matrix where columns are
the tournaments and rows are the matches in the tournaments. The
diagnostic results are:

\begin{longtable}[]{@{}ll@{}}
\toprule
Diagnostic & Result\tabularnewline
\midrule
\endhead
All \(\hat R\) values close to 1 & \textbf{NO} *lp\_\_* is
1.4\tabularnewline
Low \(\hat R\) values combined with high effective sample size (n\_eff)
& \textbf{NO}\tabularnewline
Divergences is 0 & \textbf{NO} 8\% of the target posterior was not
explored\tabularnewline
\bottomrule
\end{longtable}

Because none of the conditions were fulfilled, in the next step we will
try to improve the results by reducing the accuracy of the simulations
by increasing the value of the \emph{adapt\_delta} parameter.

The results of the attempt 1 can be seen below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Fit hierarchical uniform model}
        \PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}fit} \PY{o}{=} \PY{n}{compute\PYZus{}model}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stan\PYZus{}code/hier\PYZus{}uniform\PYZus{}prior.stan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hierarchical\PYZus{}data\PYZus{}model}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Print the summary of the fit}
        \PY{n}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using cached StanModel

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:}                mean    se\_mean        sd      2.5\%       25\%       50\%  \textbackslash{}
        mu0          14.222  0.0306316  0.518028   13.2403   13.9695    14.264   
        sigma0     0.560246  0.0731073  0.759754  0.034287  0.172624  0.381537   
        mu[0]       14.1029  0.0484593  0.477268   13.0482   13.8036   14.1453   
        mu[1]       14.2979  0.0144251  0.458663   13.3891   14.0025   14.3344   
        mu[2]       14.0964  0.0545487  0.496962   13.0192   13.7931   14.1295   
        {\ldots}             {\ldots}        {\ldots}       {\ldots}       {\ldots}       {\ldots}       {\ldots}   
        ypred[3]    14.4326  0.0903994    5.6887   3.38663    10.585    14.451   
        ypred[4]    14.3471  0.0899178    5.6869   3.39243   10.5848   14.3392   
        mu\_new       14.208  0.0255003    1.1708   12.3481   13.8682   14.2873   
        ypred\_new   14.2926  0.0919394   5.81476   2.84883   10.4361   14.4064   
        lp\_\_       -743.541    1.47587   4.89491  -752.243  -746.688  -744.196   
        
                        75\%    97.5\% n\_eff      Rhat  
        mu0         14.4845  15.0738   286    1.0193  
        sigma0     0.709618  2.13192   108   1.03272  
        mu[0]       14.4149   14.938    97   1.03988  
        mu[1]       14.5531    15.27  1011    1.0106  
        mu[2]       14.4328  14.9691    83     1.044  
        {\ldots}             {\ldots}      {\ldots}   {\ldots}       {\ldots}  
        ypred[3]    18.2019  25.6342  3960  0.999456  
        ypred[4]    18.2295  25.5183  4000   1.00017  
        mu\_new      14.5676  15.8755  2108   1.00535  
        ypred\_new   18.2223  25.4268  4000   1.00122  
        lp\_\_       -741.133  -732.58    11   1.42308  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Print additional checking of the fit}
         \PY{n}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Maximum value of the Rhat: 
1.423080255915649

Divergences:
308.0 of 4000 iterations ended with a divergence (7.7\%)
Try running with larger adapt\_delta to remove the divergences


    \end{Verbatim}

    \hypertarget{convergence-diagnostic-attempt-2}{%
\paragraph{Convergence diagnostic attempt
2}\label{convergence-diagnostic-attempt-2}}

After changing the accuracy of the simulations from 0.9 to 0.93, the
data is re-fit and following results are gained:

\begin{longtable}[]{@{}ll@{}}
\toprule
Diagnostic & Result\tabularnewline
\midrule
\endhead
All \(\hat R\) values close to 1 & OK\tabularnewline
Low \(\hat R\) values combined with high effective sample size (n\_eff)
& OK\tabularnewline
Divergences is 0 & \textbf{NO} still 2\% of the target posterior was not
explored\tabularnewline
\bottomrule
\end{longtable}

With these results we can verify that the hierarchical uniform prior
model fitting is almost successful. Although, this is not the desired
result and therefore, in the next step the further improvement is
discussed.

The results of the attempt 2 is shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} Fit hierarchical uniform model}
         \PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}fit} \PY{o}{=} \PY{n}{compute\PYZus{}model}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stan\PYZus{}code/hier\PYZus{}uniform\PYZus{}prior.stan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                                                   \PY{n}{hierarchical\PYZus{}data\PYZus{}model}\PY{p}{,} \PY{n}{adapt\PYZus{}delta}\PY{o}{=}\PY{l+m+mf}{0.93}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Print the summary of the fit}
         \PY{n}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using cached StanModel

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:}                mean    se\_mean        sd       2.5\%       25\%      50\%  \textbackslash{}
         mu0         14.1722  0.0133645   0.44123    13.3144   13.9179   14.159   
         sigma0     0.563965  0.0243783  0.571721  0.0510735  0.200409  0.40928   
         mu[0]       14.0559  0.0143581  0.480942    13.0217   13.7558  14.0839   
         mu[1]       14.2551   0.013469  0.481318    13.3542   13.9509  14.2275   
         mu[2]       14.0422  0.0138805  0.481636    12.9916     13.76   14.056   
         {\ldots}             {\ldots}        {\ldots}       {\ldots}        {\ldots}       {\ldots}      {\ldots}   
         ypred[3]    14.3333  0.0915444   5.68976    3.33591   10.4447  14.3595   
         ypred[4]    14.2131  0.0884799   5.58756     3.2083   10.4591  14.2649   
         mu\_new      14.1864  0.0184552  0.961623    12.4116   13.7922  14.1716   
         ypred\_new   14.2098  0.0896986   5.67304    2.94677   10.4409  14.1165   
         lp\_\_       -744.229   0.245898   4.09994   -752.034   -747.03 -744.541   
         
                         75\%    97.5\% n\_eff      Rhat  
         mu0         14.4377  15.0467  1090   1.00438  
         sigma0     0.731901  2.12706   550   1.00114  
         mu[0]       14.3739  14.9692  1122    1.0034  
         mu[1]       14.5544  15.2806  1277   1.00411  
         mu[2]       14.3534  14.9512  1204   1.00298  
         {\ldots}             {\ldots}      {\ldots}   {\ldots}       {\ldots}  
         ypred[3]    18.0902  25.5877  3863   0.99995  
         ypred[4]    18.0418  24.8965  3988   1.00015  
         mu\_new       14.569  16.0339  2715   1.00083  
         ypred\_new   17.8849  25.5395  4000  0.999853  
         lp\_\_       -741.593 -735.542   278   1.00407  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} Print additional checking of the fit}
         \PY{n}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Maximum value of the Rhat: 
1.0043815114485763

Divergences:
79.0 of 4000 iterations ended with a divergence (1.975\%)
Try running with larger adapt\_delta to remove the divergences


    \end{Verbatim}

    \hypertarget{successful-fitting}{%
\subsubsection{6.3.2 Successful fitting}\label{successful-fitting}}

In this section, we will modify the Stan code and use exactly the same
approach as described in pystan's workflow
(http://mc-stan.org/users/documentation/case-studies/pystan\_workflow.html,
A Successful Fit). Because the fit which uses the centered
parametrization is not successful, we should change the Stan code using
non-centered parametrization.

\textbf{Centered} parametrization of parameter \emph{mu}

\begin{verbatim}
parameters {
  ...
  real mu[J]; // Tournament specific mu
  ...
}
model {
  for (j in 1:J) // Model for computing tournament specific mu from common mu0 and sigma0
    mu[j] ~ normal(mu0, sigma0);
  ...
}
\end{verbatim}

is converted \textbf{to non-centered} parametrization

\begin{verbatim}
parameters {
  ...
  real mu_tilde[J];
}
transformed parameters {
  real mu[J];// Tournament specific mu
  for (j in 1:J)
    mu[j] = mu0 + sigma0 * mu_tilde[j];
}
model {
  for (j in 1:J) // Model for computing tournament specific mu from common mu0 and sigma0
    mu_tilde[j] ~ normal(0, 1); // Implies mu[j] ~ normal(mu0,sigma0)
  ...
}
\end{verbatim}

The full updated Stan code is shown in the next section.

\hypertarget{stan-model}{%
\paragraph{Stan model}\label{stan-model}}

The stan code of the model:

\begin{verbatim}
data {
  int<lower=0> N;  // Number of observations
  int<lower=0> J;  // Number of tournaments
  matrix[N,J] y;  // N observations for J tournaments
}
\end{verbatim}

    \begin{verbatim}
parameters {
  real mu0;             // Common mu for each J tournament's mu
  real<lower=0> sigma0; // Common std for each J tournament's mu
  real<lower=0> sigma; // Common std between tournaments
    real mu_tilde[J];
}
transformed parameters {
  real mu[J];          // Tournament specific mu
  for (j in 1:J)
    mu[j] = mu0 + sigma0 * mu_tilde[j];
}
model {
  for (j in 1:J)                   // Model for computing tournament specific mu from common mu0 and sigma0
    mu_tilde[j] ~ normal(0, 1);    // Implies mu[j] ~ normal(mu0,sigma0)
  for (j in 1:J)
    y[:,j] ~ normal(mu[j], sigma); // Model for fitting data using machine specific mu and common std
}
generated quantities {
  matrix[N,J] log_lik;    
  real ypred[J];
  real mu_new;
  real ypred_new;
  
  for (j in 1:J)
     ypred[j] = normal_rng(mu[j], sigma);   // Predictive distibutions of all the tournaments
  mu_new = normal_rng(mu0, sigma0);       // Next posterior distribution from commonly learned mu0 and sigma0
  ypred_new = normal_rng(mu_new, sigma);    // Next predictive distibutions of new tournament
  
  for (j in 1:J)
     for (n in 1:N)
        log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma); //Log-likelihood
}
\end{verbatim}

\hypertarget{convergence-diagnostic-attempt-3}{%
\paragraph{Convergence diagnostic attempt
3}\label{convergence-diagnostic-attempt-3}}

The same procedure is followed (as in the previous section) and improved
results were obtained:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.47\columnwidth}\raggedright
Diagnostic\strut
\end{minipage} & \begin{minipage}[b]{0.47\columnwidth}\raggedright
Result\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.47\columnwidth}\raggedright
All \(\hat R\) values close to 1\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
OK\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
Low \(\hat R\) values combined with high effective sample size
(n\_eff)\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
OK\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
Divergences is 0\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
GOOD ENOUGH still 0.025\% of the target posterior was not expolred and
increasing \emph{adapt\_delta} did not improve this result\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

All of these verify that hierarchical uniform prior model fitting is
successful enough. The full fit can be found in the \emph{Attachment 3}
and a shorter summary is shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Fit hierarchical uniform model}
         \PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}fit} \PY{o}{=} \PY{n}{compute\PYZus{}model}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stan\PYZus{}code/hier\PYZus{}uniform\PYZus{}prior\PYZus{}v2.stan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hierarchical\PYZus{}data\PYZus{}model}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Print the summary of the fit}
         \PY{n}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using cached StanModel

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:}                  mean     se\_mean        sd       2.5\%       25\%       50\%  \textbackslash{}
         mu0           14.1961   0.0141698  0.458058    13.2531   13.9249   14.1917   
         sigma0       0.550535   0.0179981  0.576781  0.0140076   0.18154  0.388406   
         sigma         5.66836  0.00337786  0.213634    5.26576   5.52314   5.66113   
         mu\_tilde[0] -0.207582   0.0159645  0.883688   -1.97272 -0.795004  -0.21698   
         mu\_tilde[1]   0.10843   0.0154156  0.883542   -1.68338 -0.477808  0.101281   
         {\ldots}               {\ldots}         {\ldots}       {\ldots}        {\ldots}       {\ldots}       {\ldots}   
         ypred[3]      14.4115   0.0933838   5.77547    2.91519   10.6273   14.3439   
         ypred[4]      14.1985   0.0891236   5.63667    3.05899   10.3145    14.244   
         mu\_new        14.2178   0.0179958  0.940442     12.446   13.8592   14.2051   
         ypred\_new      14.198   0.0917411   5.80221    2.83785   10.2555   14.1872   
         lp\_\_          -749.31   0.0670804   2.27085   -754.317   -750.67  -749.121   
         
                           75\%    97.5\% n\_eff      Rhat  
         mu0            14.464  15.1017  1045   1.00285  
         sigma0       0.717958  2.06309  1027   1.00309  
         sigma         5.80597  6.10786  4000  0.999766  
         mu\_tilde[0]  0.373531  1.49234  3064  0.999875  
         mu\_tilde[1]  0.691408  1.87599  3285   1.00029  
         {\ldots}               {\ldots}      {\ldots}   {\ldots}       {\ldots}  
         ypred[3]      18.2793  25.8232  3825  0.999828  
         ypred[4]      18.0424  24.8852  4000  0.999548  
         mu\_new        14.5741  16.0938  2731  0.999788  
         ypred\_new     18.1655  25.4919  4000  0.999715  
         lp\_\_         -747.698 -745.474  1146   1.00138  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Maximum value of the Rhat: 
1.0030853274280642

Divergences:
1.0 of 4000 iterations ended with a divergence (0.025\%)
Try running with larger adapt\_delta to remove the divergences


    \end{Verbatim}

    \hypertarget{hierarchical-model-with-inverse-gamma-prior}{%
\subsubsection{6.4 Hierarchical model with inverse gamma
prior}\label{hierarchical-model-with-inverse-gamma-prior}}

\hypertarget{stan-model}{%
\paragraph{Stan model}\label{stan-model}}

The stan code of the model (using non-centered parametrization):

\begin{verbatim}
data {
  int<lower=0> N;           // Number of observations
  int<lower=0> J;           // Number of tournaments
  matrix[N,J] y;            // N measurements for J tournaments
}
\end{verbatim}

    \begin{verbatim}
parameters {
  real mu0;             // Common mu for each J tournaments's mu
  real<lower=0> sigma0;         // Common std for each J tournament's mu
  real<lower=0> sigma;          // Common std
  real mu_tilde[J];
}
transformed parameters {
  real mu[J];           // Tournament specific mu
  for (j in 1:J)
    mu[j] = mu0 + sigma0 * mu_tilde[j];
}
model {
  for (j in 1:J) // Model for computing tournament specific mu from common mu0 and sigma0
    mu_tilde[j] ~ normal(0, 1); // Implies mu[j] ~ normal(mu0,sigma0)
  for (j in 1:J)
    y[:,j] ~ normal(mu[j], sigma);  // Model for fitting data using tournament specific mu and common std
}
generated quantities {
  matrix[N,J] log_lik;    
  real ypred[J];
  real mu_new;
  real ypred_new;
  
  for (j in 1:J)
     ypred[j] = normal_rng(mu[j], sigma);   // Predictive distibutions of all the tournaments
  mu_new = normal_rng(mu0, sigma0); // Next posterior distribution from commonly learned mu0 and sigma0
  ypred_new = normal_rng(mu_new, sigma);    // Next predictive distibutions of new tournament
  
  for (j in 1:J)
     for (n in 1:N)
        log_lik[n,j] = normal_lpdf(y[n,j] | mu[j], sigma); //Log-likelihood
}

\end{verbatim}

\hypertarget{convergence-diagnostic}{%
\paragraph{Convergence diagnostic}\label{convergence-diagnostic}}

The same procedure is followed (as in the previous section) and the
diagnostic results are:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.47\columnwidth}\raggedright
Diagnostic\strut
\end{minipage} & \begin{minipage}[b]{0.47\columnwidth}\raggedright
Result\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.47\columnwidth}\raggedright
All \(\hat R\) values close to 1\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
OK\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
Low \(\hat R\) values combined with high effective sample size
(n\_eff)\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
OK\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
Divergences is 0\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
GOOD ENOUGH still 0.025\% of the target posterior was not expolred and
increasing \emph{adapt\_delta} did not improve this result\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

All of these verify that hierarchical inverse gamma prior model fitting
is successful enough. The full fit can be found in the \emph{Attachment
4} and a shorter summary is shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} Fit hierarchical uniform model}
         \PY{n}{hier\PYZus{}inv\PYZus{}df}\PY{p}{,} \PY{n}{hier\PYZus{}inv\PYZus{}fit} \PY{o}{=} \PY{n}{compute\PYZus{}model}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stan\PYZus{}code/hier\PYZus{}inverse\PYZus{}gamma\PYZus{}prior\PYZus{}v2.stan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hierarchical\PYZus{}data\PYZus{}model}\PY{p}{)}
         \PY{n}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{hier\PYZus{}inv\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using cached StanModel

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:}                  mean    se\_mean        sd       2.5\%       25\%       50\%  \textbackslash{}
         mu0           14.1742  0.0106244  0.429863    13.3323   13.9126   14.1783   
         sigma0        0.55408  0.0187816  0.567502  0.0227001  0.193471  0.403468   
         mu\_tilde[0] -0.202636  0.0156438  0.883703   -1.96254 -0.760705 -0.211218   
         mu\_tilde[1]  0.115359  0.0161837  0.880342   -1.68287 -0.427827   0.10454   
         mu\_tilde[2] -0.200715  0.0146266  0.857001   -1.93516 -0.749326 -0.218871   
         {\ldots}               {\ldots}        {\ldots}       {\ldots}        {\ldots}       {\ldots}       {\ldots}   
         ypred[3]      14.5288  0.0921506   5.67531     3.5257   10.7779   14.5297   
         ypred[4]      14.1416  0.0893992    5.6541    3.05447   10.3961   14.0928   
         mu\_new        14.1745   0.017315  0.895872    12.3202   13.8097   14.1975   
         ypred\_new     14.2066  0.0899841   5.69109    3.30853   10.3106   14.0458   
         lp\_\_          -754.52  0.0668638   2.37343   -759.858  -756.017  -754.246   
         
                           75\%    97.5\% n\_eff      Rhat  
         mu0           14.4469  15.0025  1637   1.00147  
         sigma0       0.728336  2.04482   913    1.0023  
         mu\_tilde[0]   0.37144  1.55705  3191    1.0007  
         mu\_tilde[1]  0.695337  1.82562  2959   1.00076  
         mu\_tilde[2]  0.354451  1.48706  3433   1.00081  
         {\ldots}               {\ldots}      {\ldots}   {\ldots}       {\ldots}  
         ypred[3]      18.2851  26.0277  3793  0.999918  
         ypred[4]      17.9503  25.1413  4000  0.999683  
         mu\_new        14.5734  15.8751  2677   1.00043  
         ypred\_new     18.1636  25.1357  4000  0.999641  
         lp\_\_         -752.799 -750.641  1260   1.00191  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{hier\PYZus{}inv\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}inv\PYZus{}df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Maximum value of the Rhat: 
1.0022963849717355

Divergences:
1.0 of 4000 iterations ended with a divergence (0.025\%)
Try running with larger adapt\_delta to remove the divergences


    \end{Verbatim}

    \hypertarget{conclusion}{%
\subsubsection{6.5 Conclusion}\label{conclusion}}

Based on the diagnostic results, all the four models can be used for
further analysis (next section).

    \hypertarget{model-comparision-with-psis-loo-and-p_loo-cv}{%
\subsection{\texorpdfstring{7 Model comparision with PSIS-LOO and
\(P_{LOO-CV}\)}{7 Model comparision with PSIS-LOO and P\_\{LOO-CV\}}}\label{model-comparision-with-psis-loo-and-p_loo-cv}}

\begin{itemize}
\tightlist
\item
  Model selection according to the hightest LOO-CV sum
\item
  Reliability based on the \emph{k} values: \textless{} 0.7 ok,
  \textless{} 0.5 good
\end{itemize}

The PSIS-LOO values of the models can be computed using provided
\emph{psisloo} function. The function returns observation specific
\emph{k}-values and PSIS-LOO-CV values. In addition, it returns the sum
of the PSIS-LOO-CV values, hence the sum of the LOO log desnities:

\begin{equation*}
lppd_{loo-cv} = \sum_{i=1}^{N} log \left( \frac{1}{S} \sum_{s=1}^{S} p(y_i|\theta^{is}) \right)
\end{equation*}

The estimated effective number of parameters (\(P_{LOO-CV}\)) in the
model is computed as follows:

\begin{equation*}
p_{loo-cv} = lppd-lppd_{loo-cv} 
\end{equation*}

where \(lppd\) is the sum of the log densities of the posterior draws:
\begin{equation*}
lppd = \sum_{i=1}^{N} log \left( \frac{1}{S} \sum_{s=1}^{S} p(y_i|\theta^{s}) \right)
\end{equation*}

\hypertarget{comparision}{%
\subsubsection{Comparision}\label{comparision}}

All the PSIS-LOO values, estimated effective number of parameters and
\emph{k}-values are shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{compare\PYZus{}psis\PYZus{}loo}\PY{p}{(}\PY{n}{fits}\PY{o}{=}\PY{p}{[}\PY{n}{pool\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{pool\PYZus{}inv\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}inv\PYZus{}fit}\PY{p}{]}\PY{p}{,}  \PY{n}{model\PYZus{}labels}\PY{o}{=}\PY{p}{[}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pooled model with uniform prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pooled model with inverse gamma prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hierarchical model with uniform prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hierarchical model with inverse gamma prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}17}]:}                                         Models  Psisloo  P\_eff  Max k value  \textbackslash{}
         0              Pooled model with uniform prior -1056.45   1.67        -0.07   
         1        Pooled model with inverse gamma prior -1056.38   1.64        -0.01   
         2        Hierarchical model with uniform prior -1057.25   2.96         0.10   
         3  Hierarchical model with inverse gamma prior -1057.39   3.10         0.11   
         
            Min k value  Mean k value  
         0        -0.25         -0.18  
         1        -0.16         -0.11  
         2        -0.14         -0.05  
         3        -0.18         -0.04  
\end{Verbatim}
            
    \hypertarget{conclusion}{%
\subsubsection{Conclusion}\label{conclusion}}

All the models are considered very reliable with very low k-values. If
we consider towards model with best predictive accuracy, then
\textbf{Pooled model with inverse gamma prior} should be selected,
because its PSIS-LOO value is the highest (in other words the sum of log
predictive density is the highest)

    \hypertarget{posterior-predictive-checking}{%
\subsection{8 Posterior predictive
checking}\label{posterior-predictive-checking}}

In this section, for all 4 models evaluated in the previous sessions, we
will compare predictive distribution versus actual distribution for a
new tournament

\hypertarget{comparision}{%
\subsubsection{Comparision}\label{comparision}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{compare\PYZus{}predictive\PYZus{}vs\PYZus{}actual}\PY{p}{(}\PY{n}{fits}\PY{o}{=}\PY{p}{[}\PY{n}{pool\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{pool\PYZus{}inv\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}uni\PYZus{}fit}\PY{p}{,} \PY{n}{hier\PYZus{}inv\PYZus{}fit}\PY{p}{]}\PY{p}{,} \PY{n}{labels}\PY{o}{=}\PY{p}{[}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pooled model with uniform prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pooled model with inverse gamma prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hierarchical model with uniform prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         	\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hierarchical model with inverse gamma prior}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
              \PY{n}{ypred\PYZus{}accessors}\PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ypred}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ypred}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ypred\PYZus{}new}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ypred\PYZus{}new}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{new\PYZus{}data}\PY{o}{=}\PY{n}{last}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_34_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{observation}{%
\subsubsection{Observation}\label{observation}}

Posterior predictive distribution are almost identical among all models.
This can be guessed already in session 3, where the data can be seen to
by highly consistent throughout different tournaments.

Errors are considerable between prediction and actual distribution.
Albeit the posterior of the estimand seems to follow a normal
distribution, the amount of data in only one new tournament is too small
to construct a normal distribution, hence the difference between
prediction and actual values.

    \hypertarget{conclusion}{%
\subsection{9 Conclusion}\label{conclusion}}

\textbf{Problems} * Data model cannot be used for direct inference of a
single match

\textbf{Potential improvements} * Given the outcome of this report,
binomial can be a good fit as well * Data model can be improved so that
the estimand is a joint distribution of some parameters (e.g.~absolute
ranking + win degree) * Data model can be modified to fit with
multinomial model * Prior and model analysis could be improved by adding
the sensitivity analysis

\textbf{Discussion}

From the badminton domain perspective, the result is satisfiable: *
There is a visible correlation between ranking spread and win degree *
Probability of extreme outcome (towards 1 or 28) are low, and not
expected in the tournament

From the statistical inference perspective, the result is also
satisfiable * Given the domain knowledge, one would expect the
distribution of the estimand to be a normal distribution * Given the
found posteriors, we can see the result is highly data-driven * Given
two models, pooled and hierarchical, we can see that hierarchical model
ends up as pooled model

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{source-code}{%
\section{Source code}\label{source-code}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{} Import libraries}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{k+kn}{import} \PY{n+nn}{pystan}
        \PY{k+kn}{import} \PY{n+nn}{stan\PYZus{}utility}
        \PY{k+kn}{import} \PY{n+nn}{psis}
        \PY{k+kn}{import} \PY{n+nn}{warnings}
        \PY{c+c1}{\PYZsh{} For hiding warnings that do not effect the functionality of the code}
        \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Data is provided as files, 1 file contains all matches result of a tournament}
        \PY{c+c1}{\PYZsh{} We will use data from all tournaments to fit model}
        \PY{c+c1}{\PYZsh{} Except for the last one which will be used to evaluate prediction accuracy}
        \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n}{filenames} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data/}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{n}{filename} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{filenames}\PY{p}{)}\PY{p}{:}
            \PY{n}{col} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{loadtxt}\PY{p}{(}\PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data//}\PY{l+s+si}{\PYZob{}filename\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}
            \PY{k}{if} \PY{p}{(}\PY{n}{idx} \PY{o}{==} \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{filenames}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                \PY{n}{last} \PY{o}{=} \PY{n}{col}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{data}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{col}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{67}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{np\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{data}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Show the data in dataframe and change the names of the rows and columns to more descriable}
         \PY{k}{def} \PY{n+nf}{show\PYZus{}first\PYZus{}rows\PYZus{}of\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{T}\PY{p}{)}
             \PY{n}{df}\PY{o}{.}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Tournament }\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{]}
             \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{rename}\PY{p}{(}\PY{p}{\PYZob{}}\PY{n}{i}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Match }\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{index}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Show the data summary: mean, min, max, ....}
         \PY{k}{def} \PY{n+nf}{show\PYZus{}summary\PYZus{}of\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{T}\PY{p}{)}
             \PY{n}{df}\PY{o}{.}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Tournament }\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{]}
             \PY{k}{return} \PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Pooled data and its model for Stan compiler}
         \PY{n}{pooled\PYZus{}data} \PY{o}{=} \PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)}
         \PY{n}{pooled\PYZus{}data\PYZus{}model} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{N}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{pooled\PYZus{}data}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{pooled\PYZus{}data}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{beta}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}pooled\PYZus{}inv\PYZus{}g\PYZus{}data\PYZus{}model = dict(N=len(pooled\PYZus{}data), y=pooled\PYZus{}data)}
         
         \PY{c+c1}{\PYZsh{} Hierarchical data (np\PYZus{}data.T) and its model for Stan compiler}
         \PY{n}{hierarchical\PYZus{}data\PYZus{}model} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{N} \PY{o}{=} \PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{J}\PY{o}{=} \PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{y} \PY{o}{=} \PY{n}{np\PYZus{}data}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{beta}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Compile the given model and fit the given data.}
         \PY{c+c1}{\PYZsh{} Parameters:}
         \PY{c+c1}{\PYZsh{}     file\PYZus{}path: \PYZsq{}\PYZsq{}}
         \PY{c+c1}{\PYZsh{}         The path of the stan model code}
         \PY{c+c1}{\PYZsh{}     data: numpy array}
         \PY{c+c1}{\PYZsh{}         The data to be fitted}
         \PY{c+c1}{\PYZsh{}     adapt\PYZus{}delta: 0...1}
         \PY{c+c1}{\PYZsh{}        Effects to divergences, hence to the accuracy of the posterior. }
         \PY{c+c1}{\PYZsh{}        The smaller the value is the more strict the Stan model is in accepting sampels.}
         \PY{c+c1}{\PYZsh{}        The bigger the value is the easier the Stan model accepts samples. }
         \PY{c+c1}{\PYZsh{} Returns the summary of the fit and the fit itself.}
         \PY{k}{def} \PY{n+nf}{compute\PYZus{}model}\PY{p}{(}\PY{n}{file\PYZus{}path}\PY{p}{,} \PY{n}{data}\PY{p}{,} \PY{n}{adapt\PYZus{}delta}\PY{o}{=}\PY{l+m+mf}{0.9}\PY{p}{)}\PY{p}{:}
             
             \PY{c+c1}{\PYZsh{} Compile model for both separated and pooled}
             \PY{n}{model} \PY{o}{=} \PY{n}{stan\PYZus{}utility}\PY{o}{.}\PY{n}{compile\PYZus{}model}\PY{p}{(}\PY{n}{file\PYZus{}path}\PY{p}{)} 
         
             \PY{c+c1}{\PYZsh{} Fit model: adapt\PYZus{}delta is used for divergences}
             \PY{n}{fit} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{sampling}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{seed}\PY{o}{=}\PY{l+m+mi}{194838}\PY{p}{,}\PY{n}{control}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{adapt\PYZus{}delta}\PY{o}{=}\PY{n}{adapt\PYZus{}delta}\PY{p}{)}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} get summary of the fit, use pandas data frame for layout}
             \PY{n}{summary} \PY{o}{=} \PY{n}{fit}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
             \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{summary}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{summary}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{n}{summary}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{summary\PYZus{}rownames}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n}{summary}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{summary\PYZus{}colnames}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{df}\PY{p}{,} \PY{n}{fit}
         
         \PY{c+c1}{\PYZsh{} Show compact details of the fit instead of showing the whole fit}
         \PY{k}{def} \PY{n+nf}{print\PYZus{}compact\PYZus{}fit}\PY{p}{(}\PY{n}{fit\PYZus{}df}\PY{p}{,} \PY{n}{number\PYZus{}of\PYZus{}rows\PYZus{}head}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{number\PYZus{}of\PYZus{}rows\PYZus{}tail}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
             \PY{n}{df} \PY{o}{=} \PY{n}{fit\PYZus{}df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{number\PYZus{}of\PYZus{}rows\PYZus{}head}\PY{p}{)}
             \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{se\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{2.5}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{25}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{50}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{75}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{97.5}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}eff}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Rhat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{]}\PY{p}{)}
             \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{rename}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{index}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{fit\PYZus{}df}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{n}{number\PYZus{}of\PYZus{}rows\PYZus{}tail}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{n}{df}
         
         \PY{c+c1}{\PYZsh{} Show key details of the checking of the fit: rhat and divergences}
         \PY{k}{def} \PY{n+nf}{print\PYZus{}compact\PYZus{}fit\PYZus{}checking}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{df}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}Check the maximum value of the Rhat}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Maximum value of the Rhat: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Rhat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Check divergences}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Divergences:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{stan\PYZus{}utility}\PY{o}{.}\PY{n}{check\PYZus{}div}\PY{p}{(}\PY{n}{fit}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             
         \PY{c+c1}{\PYZsh{} Compare PSIS\PYZhy{}LOO values}
         \PY{k}{def} \PY{n+nf}{compare\PYZus{}psis\PYZus{}loo}\PY{p}{(}\PY{n}{fits}\PY{p}{,} \PY{n}{model\PYZus{}labels}\PY{p}{)}\PY{p}{:}
             \PY{n}{psis\PYZus{}loos}\PY{p}{,} \PY{n}{p\PYZus{}effs}\PY{p}{,} \PY{n}{k\PYZus{}max}\PY{p}{,} \PY{n}{k\PYZus{}min}\PY{p}{,} \PY{n}{k\PYZus{}mean} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{fit} \PY{o+ow}{in} \PY{n}{fits}\PY{p}{:}
                 \PY{n}{psis\PYZus{}loo}\PY{p}{,} \PY{n}{p\PYZus{}eff}\PY{p}{,} \PY{n}{ks} \PY{o}{=} \PY{n}{extract\PYZus{}psis\PYZus{}loo}\PY{p}{(}\PY{n}{fit}\PY{p}{)}
                 \PY{n}{psis\PYZus{}loos}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{psis\PYZus{}loo}\PY{p}{)}
                 \PY{n}{p\PYZus{}effs}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{p\PYZus{}eff}\PY{p}{)}
                 \PY{n}{k\PYZus{}max}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{ks}\PY{p}{)}\PY{p}{)}
                 \PY{n}{k\PYZus{}min}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{n}{ks}\PY{p}{)}\PY{p}{)}
                 \PY{n}{k\PYZus{}mean}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{ks}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Models}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{model\PYZus{}labels}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Psisloo}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{psis\PYZus{}loos}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P\PYZus{}eff}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{p\PYZus{}effs}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Max k value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{k\PYZus{}max}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Min k value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{k\PYZus{}min}\PY{p}{,}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean k value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{k\PYZus{}mean}
             \PY{p}{\PYZcb{}}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{df}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Get the effective sample size of the parameters}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}p\PYZus{}eff}\PY{p}{(}\PY{n}{log\PYZus{}lik}\PY{p}{,} \PY{n}{lppd\PYZus{}loocv}\PY{p}{)}\PY{p}{:}    
             \PY{n}{likelihoods} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{n}{log\PYZus{}likelihood}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{log\PYZus{}likelihood} \PY{o+ow}{in} \PY{n}{log\PYZus{}lik}\PY{p}{]}\PY{p}{)}
             \PY{n}{num\PYZus{}sim}\PY{p}{,} \PY{n}{num\PYZus{}obs} \PY{o}{=} \PY{n}{likelihoods}\PY{o}{.}\PY{n}{shape}
             \PY{n}{lppd} \PY{o}{=} \PY{l+m+mi}{0}
             \PY{k}{for} \PY{n}{obs} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}obs}\PY{p}{)}\PY{p}{:}
                 \PY{n}{lppd} \PY{o}{+}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{likelihoods}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{obs}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{n}{num\PYZus{}sim}\PY{p}{)}
             
             \PY{n}{p\PYZus{}eff} \PY{o}{=} \PY{n}{lppd} \PY{o}{\PYZhy{}} \PY{n}{lppd\PYZus{}loocv}
             \PY{k}{return} \PY{n}{p\PYZus{}eff}
         
         \PY{k}{def} \PY{n+nf}{extract\PYZus{}psis\PYZus{}loo}\PY{p}{(}\PY{n}{samples}\PY{p}{,} \PY{n}{plot\PYZus{}title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
             \PY{n}{log\PYZus{}lik\PYZus{}matrix} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{asarray}\PY{p}{(}\PY{p}{[}\PY{n}{single\PYZus{}sample}\PY{o}{.}\PY{n}{flatten}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{single\PYZus{}sample} \PY{o+ow}{in} \PY{n}{samples}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log\PYZus{}lik}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}
             \PY{n}{loo}\PY{p}{,} \PY{n}{loos}\PY{p}{,} \PY{n}{ks} \PY{o}{=} \PY{n}{psis}\PY{o}{.}\PY{n}{psisloo}\PY{p}{(}\PY{n}{log\PYZus{}lik\PYZus{}matrix}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Calculate p\PYZus{}eff}
             \PY{n}{p\PYZus{}eff} \PY{o}{=} \PY{n}{get\PYZus{}p\PYZus{}eff}\PY{p}{(}\PY{n}{log\PYZus{}lik\PYZus{}matrix}\PY{p}{,} \PY{n}{loo}\PY{p}{)}
         
             \PY{k}{return} \PY{n}{loo}\PY{p}{,} \PY{n}{p\PYZus{}eff}\PY{p}{,} \PY{n}{ks}
         
         \PY{k}{def} \PY{n+nf}{compare\PYZus{}predictive\PYZus{}vs\PYZus{}actual}\PY{p}{(}\PY{n}{fits}\PY{p}{,} \PY{n}{labels}\PY{p}{,} \PY{n}{ypred\PYZus{}accessors}\PY{p}{,} \PY{n}{new\PYZus{}data}\PY{p}{)}\PY{p}{:}
             \PY{n}{bar\PYZus{}width} \PY{o}{=} \PY{l+m+mf}{0.3}
             \PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{sharey}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{,} \PY{n}{subplot\PYZus{}kw}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{aspect}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{plots} \PY{o}{=} \PY{p}{[}\PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}
             
             \PY{c+c1}{\PYZsh{} Group new\PYZus{}data }
             \PY{c+c1}{\PYZsh{} e.g. [1,2,3,2,2] =\PYZgt{} [1: 0.2, 2: 0.6, 3: 0.2]}
             \PY{n}{aggregated} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{new\PYZus{}data}\PY{p}{:}
                 \PY{k}{if} \PY{n}{i} \PY{o+ow}{in} \PY{n}{aggregated}\PY{p}{:}
                     \PY{n}{aggregated}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                 \PY{k}{else}\PY{p}{:}
                     \PY{n}{aggregated}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
         
             \PY{c+c1}{\PYZsh{} Dist of new\PYZus{}data}
             \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{aggregated}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{aggregated}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{new\PYZus{}data}\PY{p}{)}
             
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{fits}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{n}{fit} \PY{o}{=} \PY{n}{fits}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                 \PY{n}{label} \PY{o}{=} \PY{n}{labels}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                 \PY{n}{ypred\PYZus{}accessor} \PY{o}{=} \PY{n}{ypred\PYZus{}accessors}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                 \PY{n}{ypred} \PY{o}{=} \PY{n}{fit}\PY{o}{.}\PY{n}{extract}\PY{p}{(}\PY{n}{permuted}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{[}\PY{n}{ypred\PYZus{}accessor}\PY{p}{]}
                 
                 \PY{c+c1}{\PYZsh{} Dist of ypred for new\PYZus{}data values}
                 \PY{n}{y2\PYZus{}dist} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{ypred}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{ypred}\PY{p}{)}\PY{p}{)}
                 \PY{n}{y2} \PY{o}{=} \PY{n}{y2\PYZus{}dist}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 
                 \PY{n}{partial\PYZus{}plt} \PY{o}{=} \PY{n}{plots}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                 \PY{n}{partial\PYZus{}plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{width}\PY{o}{=}\PY{n}{bar\PYZus{}width}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Actual}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{n}{partial\PYZus{}plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{x}\PY{o}{\PYZhy{}}\PY{n}{bar\PYZus{}width}\PY{p}{,}\PY{n}{y2}\PY{p}{,}\PY{n}{width}\PY{o}{=}\PY{n}{bar\PYZus{}width}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Prediction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{n}{partial\PYZus{}plt}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{n}{label}\PY{p}{)}
                 \PY{n}{partial\PYZus{}plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{show\PYZus{}attachments}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} Attachment 1: Fit of pooled model with uniform prior \PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{n}{pool\PYZus{}uni\PYZus{}fit}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} Attachment 2: Fit of pooled model with inverse gamma prior \PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{n}{pool\PYZus{}inv\PYZus{}fit}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} Attachment 3: Fit of hierarchical model with uniform prior \PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{n}{hier\PYZus{}uni\PYZus{}fit}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} Attachment 4: Fit of hierarchical model with inverse gamma prior \PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{n}{hier\PYZus{}inv\PYZus{}fit}\PY{p}{)}\PY{p}{;} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
             
         \PY{c+c1}{\PYZsh{}show\PYZus{}attachments()}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#\#\#\#\#\#\#\#\#\# Attachment 1: Fit of pooled model with uniform prior \#\#\#\#\#\#\#\#\#\#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

Inference for Stan model: anon\_model\_9b8e95f23a292c6baefb5978c5223890.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

               mean se\_mean     sd   2.5\%    25\%    50\%    75\%  97.5\%  n\_eff   Rhat
mu            14.19  6.0e-3   0.31  13.56  13.98   14.2  14.41  14.82   2712    1.0
sigma          5.66  4.4e-3   0.22   5.24   5.51   5.65   5.81   6.13   2577    1.0
log\_lik[0]    -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[1]    -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[2]     -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[3]    -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[4]    -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[5]    -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[6]    -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[7]    -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[8]    -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[9]    -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[10]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[11]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[12]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[13]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[14]   -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[15]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[16]   -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[17]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[18]    -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[19]   -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[20]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[21]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[22]   -4.16  2.3e-3   0.13  -4.42  -4.24  -4.15  -4.07  -3.94   2920    1.0
log\_lik[23]   -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[24]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[25]   -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[26]   -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[27]   -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[28]   -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[29]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[30]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[31]   -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[32]   -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[33]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[34]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[35]   -4.48  2.8e-3   0.15  -4.79  -4.58  -4.48  -4.38  -4.21   2940    1.0
log\_lik[36]   -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[37]   -4.16  2.3e-3   0.13  -4.42  -4.24  -4.15  -4.07  -3.94   2920    1.0
log\_lik[38]    -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[39]   -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[40]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[41]   -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[42]   -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[43]   -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[44]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[45]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[46]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[47]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[48]   -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[49]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[50]   -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[51]   -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[52]   -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[53]   -4.28  2.6e-3   0.13  -4.56  -4.37  -4.28  -4.19  -4.02   2565    1.0
log\_lik[54]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[55]    -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[56]   -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[57]   -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[58]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[59]   -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[60]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[61]   -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[62]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[63]   -3.46  1.4e-3   0.07  -3.62  -3.51  -3.46  -3.41  -3.32   2738    1.0
log\_lik[64]    -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[65]   -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[66]   -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[67]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[68]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[69]   -3.46  1.4e-3   0.07  -3.62  -3.51  -3.46  -3.41  -3.32   2738    1.0
log\_lik[70]   -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[71]   -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[72]   -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[73]    -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[74]   -5.22  3.8e-3   0.21  -5.65  -5.36  -5.22  -5.08  -4.85   2963    1.0
log\_lik[75]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[76]   -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[77]   -2.65  7.8e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   2561    1.0
log\_lik[78]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[79]   -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[80]   -3.46  1.4e-3   0.07  -3.62  -3.51  -3.46  -3.41  -3.32   2738    1.0
log\_lik[81]   -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[82]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[83]   -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[84]   -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[85]   -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[86]   -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[87]   -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[88]   -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[89]   -4.16  2.3e-3   0.13  -4.42  -4.24  -4.15  -4.07  -3.94   2920    1.0
log\_lik[90]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[91]   -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[92]   -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[93]   -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[94]   -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[95]   -2.65  7.8e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   2561    1.0
log\_lik[96]   -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[97]   -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[98]   -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[99]   -4.62  3.1e-3   0.16  -4.95  -4.72  -4.61  -4.51   -4.3   2548    1.0
log\_lik[100]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[101]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[102]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[103]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[104]  -4.48  2.8e-3   0.15  -4.79  -4.58  -4.48  -4.38  -4.21   2940    1.0
log\_lik[105]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[106]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[107]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[108]  -3.46  1.4e-3   0.07  -3.62  -3.51  -3.46  -3.41  -3.32   2738    1.0
log\_lik[109]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[110]  -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[111]  -2.65  7.8e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   2561    1.0
log\_lik[112]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[113]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[114]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[115]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[116]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[117]  -4.48  2.8e-3   0.15  -4.79  -4.58  -4.48  -4.38  -4.21   2940    1.0
log\_lik[118]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[119]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[120]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[121]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[122]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[123]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[124]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[125]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[126]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[127]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[128]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[129]  -4.28  2.6e-3   0.13  -4.56  -4.37  -4.28  -4.19  -4.02   2565    1.0
log\_lik[130]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[131]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[132]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[133]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[134]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[135]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[136]  -4.28  2.6e-3   0.13  -4.56  -4.37  -4.28  -4.19  -4.02   2565    1.0
log\_lik[137]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[138]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[139]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[140]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[141]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[142]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[143]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[144]  -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[145]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[146]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[147]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[148]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[149]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[150]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[151]  -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[152]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[153]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[154]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[155]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[156]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[157]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[158]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[159]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[160]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[161]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[162]  -3.87  1.9e-3    0.1  -4.08  -3.94  -3.86   -3.8  -3.68   2892    1.0
log\_lik[163]  -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[164]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[165]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[166]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[167]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[168]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[169]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[170]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[171]  -4.84  3.3e-3   0.18   -5.2  -4.96  -4.83  -4.71  -4.52   2953    1.0
log\_lik[172]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[173]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[174]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[175]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[176]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[177]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[178]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[179]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[180]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[181]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[182]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[183]  -3.87  1.9e-3    0.1  -4.08  -3.94  -3.86   -3.8  -3.68   2892    1.0
log\_lik[184]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[185]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[186]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[187]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[188]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[189]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[190]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[191]  -4.16  2.3e-3   0.13  -4.42  -4.24  -4.15  -4.07  -3.94   2920    1.0
log\_lik[192]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[193]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[194]  -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[195]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[196]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[197]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[198]  -2.65  7.8e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   2561    1.0
log\_lik[199]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[200]  -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[201]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[202]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[203]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[204]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[205]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[206]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[207]  -4.16  2.3e-3   0.13  -4.42  -4.24  -4.15  -4.07  -3.94   2920    1.0
log\_lik[208]  -4.84  3.3e-3   0.18   -5.2  -4.96  -4.83  -4.71  -4.52   2953    1.0
log\_lik[209]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[210]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[211]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[212]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[213]  -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[214]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[215]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[216]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[217]  -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[218]  -4.28  2.6e-3   0.13  -4.56  -4.37  -4.28  -4.19  -4.02   2565    1.0
log\_lik[219]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[220]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[221]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[222]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[223]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[224]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[225]  -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[226]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[227]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[228]  -3.02  9.3e-4   0.05  -3.12  -3.05  -3.01  -2.98  -2.92   2698    1.0
log\_lik[229]  -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[230]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[231]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[232]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[233]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[234]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[235]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[236]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[237]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[238]  -5.22  3.8e-3   0.21  -5.65  -5.36  -5.22  -5.08  -4.85   2963    1.0
log\_lik[239]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[240]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[241]  -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[242]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[243]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[244]  -4.84  3.3e-3   0.18   -5.2  -4.96  -4.83  -4.71  -4.52   2953    1.0
log\_lik[245]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[246]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[247]  -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[248]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[249]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[250]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[251]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[252]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[253]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[254]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[255]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[256]  -4.62  3.1e-3   0.16  -4.95  -4.72  -4.61  -4.51   -4.3   2548    1.0
log\_lik[257]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[258]  -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[259]  -4.16  2.3e-3   0.13  -4.42  -4.24  -4.15  -4.07  -3.94   2920    1.0
log\_lik[260]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[261]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[262]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[263]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[264]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[265]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[266]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[267]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[268]  -5.38  4.3e-3   0.22  -5.83  -5.52  -5.37  -5.23  -4.96   2533    1.0
log\_lik[269]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[270]  -3.98  2.2e-3   0.11  -4.21  -4.05  -3.97   -3.9  -3.76   2595    1.0
log\_lik[271]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[272]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[273]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[274]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[275]  -3.87  1.9e-3    0.1  -4.08  -3.94  -3.86   -3.8  -3.68   2892    1.0
log\_lik[276]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[277]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[278]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[279]  -4.28  2.6e-3   0.13  -4.56  -4.37  -4.28  -4.19  -4.02   2565    1.0
log\_lik[280]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[281]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[282]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[283]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[284]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[285]  -3.18  1.1e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2746    1.0
log\_lik[286]  -5.22  3.8e-3   0.21  -5.65  -5.36  -5.22  -5.08  -4.85   2963    1.0
log\_lik[287]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[288]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[289]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[290]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[291]  -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[292]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[293]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[294]  -4.62  3.1e-3   0.16  -4.95  -4.72  -4.61  -4.51   -4.3   2548    1.0
log\_lik[295]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[296]  -3.08  9.7e-4   0.05  -3.18  -3.11  -3.08  -3.04  -2.98   2793    1.0
log\_lik[297]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[298]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[299]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[300]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[301]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[302]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[303]  -4.28  2.6e-3   0.13  -4.56  -4.37  -4.28  -4.19  -4.02   2565    1.0
log\_lik[304]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[305]  -2.68  7.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   2661    1.0
log\_lik[306]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[307]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[308]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[309]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[310]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[311]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[312]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[313]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[314]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[315]  -2.88  8.5e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2565    1.0
log\_lik[316]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[317]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[318]  -2.66  7.8e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   2547    1.0
log\_lik[319]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[320]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[321]  -3.71  1.8e-3   0.09  -3.89  -3.77   -3.7  -3.64  -3.53   2641    1.0
log\_lik[322]  -2.65  7.8e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   2561    1.0
log\_lik[323]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[324]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[325]  -2.73  7.4e-4   0.04  -2.81  -2.76  -2.73   -2.7  -2.65   2942    1.0
log\_lik[326]  -3.25  1.2e-3   0.06  -3.38   -3.3  -3.25  -3.21  -3.14   2754    1.0
log\_lik[327]  -2.93  8.4e-4   0.05  -3.02  -2.96  -2.93   -2.9  -2.84   2853    1.0
log\_lik[328]  -2.78  8.1e-4   0.04  -2.86   -2.8  -2.78  -2.75   -2.7   2484    1.0
log\_lik[329]  -4.84  3.3e-3   0.18   -5.2  -4.96  -4.83  -4.71  -4.52   2953    1.0
log\_lik[330]  -3.38  1.3e-3   0.07  -3.52  -3.43  -3.38  -3.33  -3.25   2803    1.0
log\_lik[331]  -3.61  1.6e-3   0.08  -3.78  -3.66   -3.6  -3.55  -3.46   2853    1.0
log\_lik[332]   -2.7  7.9e-4   0.04  -2.79  -2.73   -2.7  -2.68  -2.63   2483    1.0
log\_lik[333]  -2.81  7.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.73   2911    1.0
log\_lik[334]  -3.46  1.4e-3   0.07  -3.62  -3.51  -3.46  -3.41  -3.32   2738    1.0
ypred         14.29    0.09    5.7   3.43  10.36  14.28   18.2   25.6   4000    1.0
lp\_\_         -746.0    0.02   1.01 -748.7 -746.4 -745.7 -745.3 -745.0   1637    1.0

Samples were drawn using NUTS at Sun Dec  9 13:47:05 2018.
For each parameter, n\_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).

\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#\#\#\#\#\#\# Attachment 2: Fit of pooled model with inverse gamma prior \#\#\#\#\#\#\#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

Inference for Stan model: anon\_model\_fa6169eb72725ff16af37d26935097d5.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

               mean se\_mean     sd   2.5\%    25\%    50\%    75\%  97.5\%  n\_eff   Rhat
mu            14.19  6.6e-3   0.31  13.58  13.98  14.19   14.4  14.81   2228    1.0
sigmaSq       31.82    0.05   2.43   27.5   30.1  31.69  33.37  36.82   2719    1.0
sigma          5.64  4.1e-3   0.21   5.24   5.49   5.63   5.78   6.07   2741    1.0
log\_lik[0]    -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[1]    -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[2]     -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[3]    -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[4]    -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[5]    -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[6]    -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[7]    -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[8]    -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[9]    -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[10]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[11]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[12]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[13]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[14]   -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[15]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[16]   -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[17]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[18]    -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[19]   -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[20]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[21]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[22]   -4.17  2.6e-3   0.12  -4.41  -4.25  -4.16  -4.09  -3.95   2091    1.0
log\_lik[23]   -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[24]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[25]   -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[26]   -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[27]   -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[28]   -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[29]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[30]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[31]   -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[32]   -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[33]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[34]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[35]    -4.5  3.1e-3   0.14  -4.79  -4.59  -4.49   -4.4  -4.23   2112    1.0
log\_lik[36]   -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[37]   -4.17  2.6e-3   0.12  -4.41  -4.25  -4.16  -4.09  -3.95   2091    1.0
log\_lik[38]    -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[39]   -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[40]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[41]   -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[42]   -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[43]   -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[44]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[45]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[46]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[47]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[48]   -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[49]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[50]   -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[51]   -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[52]   -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[53]   -4.29  2.7e-3   0.14  -4.57  -4.38  -4.28   -4.2  -4.04   2574    1.0
log\_lik[54]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[55]    -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[56]   -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[57]   -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[58]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[59]   -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[60]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[61]   -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[62]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[63]   -3.47  1.6e-3   0.08  -3.62  -3.51  -3.46  -3.41  -3.33   2351    1.0
log\_lik[64]    -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[65]   -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[66]   -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[67]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[68]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[69]   -3.47  1.6e-3   0.08  -3.62  -3.51  -3.46  -3.41  -3.33   2351    1.0
log\_lik[70]   -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[71]   -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[72]   -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[73]    -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[74]   -5.24  4.2e-3    0.2  -5.63  -5.37  -5.24  -5.11  -4.88   2161    1.0
log\_lik[75]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[76]   -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[77]   -2.65  7.3e-4   0.04  -2.73  -2.67  -2.65  -2.62  -2.58   2690    1.0
log\_lik[78]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[79]   -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[80]   -3.47  1.6e-3   0.08  -3.62  -3.51  -3.46  -3.41  -3.33   2351    1.0
log\_lik[81]   -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[82]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[83]   -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[84]   -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[85]   -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[86]   -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[87]   -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[88]   -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[89]   -4.17  2.6e-3   0.12  -4.41  -4.25  -4.16  -4.09  -3.95   2091    1.0
log\_lik[90]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[91]   -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[92]   -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[93]   -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[94]   -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[95]   -2.65  7.3e-4   0.04  -2.73  -2.67  -2.65  -2.62  -2.58   2690    1.0
log\_lik[96]   -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[97]   -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[98]   -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[99]   -4.63  3.2e-3   0.16  -4.96  -4.73  -4.62  -4.52  -4.33   2624    1.0
log\_lik[100]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[101]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[102]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[103]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[104]   -4.5  3.1e-3   0.14  -4.79  -4.59  -4.49   -4.4  -4.23   2112    1.0
log\_lik[105]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[106]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[107]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[108]  -3.47  1.6e-3   0.08  -3.62  -3.51  -3.46  -3.41  -3.33   2351    1.0
log\_lik[109]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[110]  -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[111]  -2.65  7.3e-4   0.04  -2.73  -2.67  -2.65  -2.62  -2.58   2690    1.0
log\_lik[112]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[113]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[114]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[115]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[116]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[117]   -4.5  3.1e-3   0.14  -4.79  -4.59  -4.49   -4.4  -4.23   2112    1.0
log\_lik[118]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[119]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[120]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[121]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[122]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[123]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[124]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[125]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[126]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[127]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[128]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[129]  -4.29  2.7e-3   0.14  -4.57  -4.38  -4.28   -4.2  -4.04   2574    1.0
log\_lik[130]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[131]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[132]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[133]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[134]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[135]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[136]  -4.29  2.7e-3   0.14  -4.57  -4.38  -4.28   -4.2  -4.04   2574    1.0
log\_lik[137]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[138]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[139]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[140]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[141]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[142]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[143]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[144]  -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[145]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[146]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[147]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[148]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[149]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[150]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[151]  -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[152]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[153]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[154]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[155]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[156]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[157]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[158]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[159]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[160]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[161]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[162]  -3.88  2.2e-3    0.1  -4.08  -3.94  -3.87  -3.81  -3.69   2077    1.0
log\_lik[163]  -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[164]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[165]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[166]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[167]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[168]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[169]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[170]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[171]  -4.85  3.6e-3   0.17  -5.19  -4.96  -4.85  -4.74  -4.54   2136    1.0
log\_lik[172]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[173]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[174]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[175]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[176]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[177]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[178]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[179]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[180]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[181]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[182]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[183]  -3.88  2.2e-3    0.1  -4.08  -3.94  -3.87  -3.81  -3.69   2077    1.0
log\_lik[184]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[185]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[186]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[187]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[188]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[189]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[190]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[191]  -4.17  2.6e-3   0.12  -4.41  -4.25  -4.16  -4.09  -3.95   2091    1.0
log\_lik[192]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[193]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[194]  -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[195]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[196]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[197]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[198]  -2.65  7.3e-4   0.04  -2.73  -2.67  -2.65  -2.62  -2.58   2690    1.0
log\_lik[199]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[200]  -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[201]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[202]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[203]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[204]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[205]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[206]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[207]  -4.17  2.6e-3   0.12  -4.41  -4.25  -4.16  -4.09  -3.95   2091    1.0
log\_lik[208]  -4.85  3.6e-3   0.17  -5.19  -4.96  -4.85  -4.74  -4.54   2136    1.0
log\_lik[209]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[210]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[211]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[212]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[213]  -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[214]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[215]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[216]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[217]  -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[218]  -4.29  2.7e-3   0.14  -4.57  -4.38  -4.28   -4.2  -4.04   2574    1.0
log\_lik[219]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[220]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[221]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[222]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[223]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[224]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[225]  -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[226]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[227]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[228]  -3.01  1.0e-3   0.05  -3.11  -3.05  -3.01  -2.98  -2.92   2272    1.0
log\_lik[229]  -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[230]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[231]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[232]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[233]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[234]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[235]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[236]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[237]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[238]  -5.24  4.2e-3    0.2  -5.63  -5.37  -5.24  -5.11  -4.88   2161    1.0
log\_lik[239]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[240]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[241]  -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[242]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[243]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[244]  -4.85  3.6e-3   0.17  -5.19  -4.96  -4.85  -4.74  -4.54   2136    1.0
log\_lik[245]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[246]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[247]  -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[248]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[249]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[250]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[251]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[252]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[253]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[254]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[255]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[256]  -4.63  3.2e-3   0.16  -4.96  -4.73  -4.62  -4.52  -4.33   2624    1.0
log\_lik[257]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[258]  -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[259]  -4.17  2.6e-3   0.12  -4.41  -4.25  -4.16  -4.09  -3.95   2091    1.0
log\_lik[260]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[261]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[262]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[263]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[264]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[265]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[266]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[267]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[268]   -5.4  4.2e-3   0.22  -5.85  -5.55  -5.39  -5.25  -4.99   2694    1.0
log\_lik[269]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[270]  -3.98  2.3e-3   0.11  -4.22  -4.06  -3.98  -3.91  -3.78   2513    1.0
log\_lik[271]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[272]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[273]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[274]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[275]  -3.88  2.2e-3    0.1  -4.08  -3.94  -3.87  -3.81  -3.69   2077    1.0
log\_lik[276]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[277]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[278]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[279]  -4.29  2.7e-3   0.14  -4.57  -4.38  -4.28   -4.2  -4.04   2574    1.0
log\_lik[280]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[281]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[282]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[283]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[284]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[285]  -3.18  1.2e-3   0.06   -3.3  -3.22  -3.18  -3.14  -3.07   2205    1.0
log\_lik[286]  -5.24  4.2e-3    0.2  -5.63  -5.37  -5.24  -5.11  -4.88   2161    1.0
log\_lik[287]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[288]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[289]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[290]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[291]  -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[292]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[293]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[294]  -4.63  3.2e-3   0.16  -4.96  -4.73  -4.62  -4.52  -4.33   2624    1.0
log\_lik[295]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[296]  -3.08  1.1e-3   0.05  -3.18  -3.11  -3.07  -3.04  -2.98   2186    1.0
log\_lik[297]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[298]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[299]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[300]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[301]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[302]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[303]  -4.29  2.7e-3   0.14  -4.57  -4.38  -4.28   -4.2  -4.04   2574    1.0
log\_lik[304]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[305]  -2.67  7.8e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   2296    1.0
log\_lik[306]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[307]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[308]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[309]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[310]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[311]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[312]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[313]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[314]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[315]  -2.88  8.9e-4   0.04  -2.97  -2.91  -2.88  -2.85   -2.8   2399    1.0
log\_lik[316]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[317]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[318]  -2.66  7.4e-4   0.04  -2.74  -2.68  -2.66  -2.63  -2.59   2733    1.0
log\_lik[319]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[320]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[321]  -3.71  1.9e-3   0.09   -3.9  -3.77  -3.71  -3.65  -3.54   2438    1.0
log\_lik[322]  -2.65  7.3e-4   0.04  -2.73  -2.67  -2.65  -2.62  -2.58   2690    1.0
log\_lik[323]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[324]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[325]  -2.73  8.1e-4   0.04   -2.8  -2.75  -2.72   -2.7  -2.65   2145    1.0
log\_lik[326]  -3.26  1.3e-3   0.06  -3.38  -3.29  -3.25  -3.21  -3.14   2263    1.0
log\_lik[327]  -2.93  9.6e-4   0.04  -3.02  -2.95  -2.93   -2.9  -2.85   2055    1.0
log\_lik[328]  -2.77  8.1e-4   0.04  -2.86   -2.8  -2.77  -2.75   -2.7   2555    1.0
log\_lik[329]  -4.85  3.6e-3   0.17  -5.19  -4.96  -4.85  -4.74  -4.54   2136    1.0
log\_lik[330]  -3.38  1.5e-3   0.07  -3.52  -3.42  -3.38  -3.34  -3.25   2112    1.0
log\_lik[331]  -3.61  1.8e-3   0.08  -3.77  -3.67  -3.61  -3.56  -3.46   2080    1.0
log\_lik[332]   -2.7  7.6e-4   0.04  -2.78  -2.73   -2.7  -2.67  -2.63   2683    1.0
log\_lik[333]  -2.81  8.7e-4   0.04  -2.89  -2.84  -2.81  -2.78  -2.74   2054    1.0
log\_lik[334]  -3.47  1.6e-3   0.08  -3.62  -3.51  -3.46  -3.41  -3.33   2351    1.0
ypred         14.26    0.09   5.61   3.24  10.48  14.33   18.0  25.22   3898    1.0
lp\_\_         -751.2    0.03   1.01 -753.9 -751.5 -750.9 -750.4 -750.2   1496    1.0

Samples were drawn using NUTS at Sun Dec  9 13:47:30 2018.
For each parameter, n\_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).

\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#\#\#\#\#\#\# Attachment 3: Fit of hierarchical model with uniform prior \#\#\#\#\#\#\#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

Inference for Stan model: anon\_model\_c4c17a1f535ecd44756a69898a3750cd.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

                mean se\_mean     sd   2.5\%    25\%    50\%    75\%  97.5\%  n\_eff   Rhat
mu0             14.2    0.01   0.46  13.25  13.92  14.19  14.46   15.1   1045    1.0
sigma0          0.55    0.02   0.58   0.01   0.18   0.39   0.72   2.06   1027    1.0
sigma           5.67  3.4e-3   0.21   5.27   5.52   5.66   5.81   6.11   4000    1.0
mu\_tilde[0]    -0.21    0.02   0.88  -1.97   -0.8  -0.22   0.37   1.49   3064    1.0
mu\_tilde[1]     0.11    0.02   0.88  -1.68  -0.48    0.1   0.69   1.88   3285    1.0
mu\_tilde[2]    -0.21    0.02   0.88  -1.89   -0.8  -0.22   0.37   1.52   2993    1.0
mu\_tilde[3]     0.33    0.02   0.85  -1.43   -0.2   0.35    0.9   1.95   2605    1.0
mu\_tilde[4]    -0.03    0.01   0.86  -1.74   -0.6  -0.02   0.53   1.71   3305    1.0
mu[0]          14.06  7.6e-3   0.48  12.98  13.79  14.09  14.37  14.95   4000    1.0
mu[1]          14.25  7.4e-3   0.47  13.31  13.95  14.25  14.55  15.23   4000    1.0
mu[2]          14.06  7.6e-3   0.48  13.03  13.77  14.08  14.38  14.95   4000    1.0
mu[3]          14.41  7.8e-3    0.5  13.54  14.06  14.36   14.7   15.5   4000    1.0
mu[4]          14.18  7.5e-3   0.47  13.22  13.89  14.19  14.47  15.12   4000    1.0
log\_lik[0,0]   -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[1,0]   -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[2,0]   -2.72  7.2e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[3,0]   -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[4,0]   -3.04  1.2e-3   0.08  -3.22  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[5,0]   -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[6,0]   -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[7,0]   -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[8,0]   -3.94  2.3e-3   0.15  -4.22  -4.03  -3.94  -3.85  -3.63   4000    1.0
log\_lik[9,0]   -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[10,0]  -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[11,0]  -3.06  1.2e-3   0.08  -3.21   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[12,0]  -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[13,0]  -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[14,0]  -3.94  2.3e-3   0.15  -4.22  -4.03  -3.94  -3.85  -3.63   4000    1.0
log\_lik[15,0]  -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[16,0]   -2.8  8.2e-4   0.05  -2.91  -2.84   -2.8  -2.77   -2.7   4000    1.0
log\_lik[17,0]  -3.06  1.2e-3   0.08  -3.21   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[18,0]  -2.72  7.2e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[19,0]  -3.41  1.7e-3   0.11  -3.66  -3.47   -3.4  -3.34  -3.22   4000    1.0
log\_lik[20,0]  -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[21,0]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[22,0]   -4.2  2.7e-3   0.17  -4.59   -4.3  -4.19  -4.09   -3.9   4000    1.0
log\_lik[23,0]  -2.91  9.9e-4   0.06  -3.04  -2.95  -2.92  -2.88  -2.78   4000    1.0
log\_lik[24,0]  -3.06  1.2e-3   0.08  -3.21   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[25,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.18  -3.04   4000    1.0
log\_lik[26,0]  -3.64  2.0e-3   0.13  -3.93  -3.71  -3.63  -3.56  -3.42   4000    1.0
log\_lik[27,0]  -2.72  7.0e-4   0.04  -2.81  -2.75  -2.72  -2.69  -2.64   4000    1.0
log\_lik[28,0]  -3.04  1.2e-3   0.08  -3.22  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[29,0]  -3.06  1.2e-3   0.08  -3.21   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[30,0]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[31,0]  -2.72  7.0e-4   0.04  -2.81  -2.75  -2.72  -2.69  -2.64   4000    1.0
log\_lik[32,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.18  -3.04   4000    1.0
log\_lik[33,0]  -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[34,0]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[35,0]  -4.53  3.1e-3   0.19  -4.96  -4.64  -4.51   -4.4  -4.18   4000    1.0
log\_lik[36,0]  -3.04  1.2e-3   0.08  -3.22  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[37,0]   -4.2  2.7e-3   0.17  -4.59   -4.3  -4.19  -4.09   -3.9   4000    1.0
log\_lik[38,0]  -2.72  7.2e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[39,0]  -3.94  2.3e-3   0.15  -4.22  -4.03  -3.94  -3.85  -3.63   4000    1.0
log\_lik[40,0]  -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[41,0]  -3.21  1.4e-3   0.09  -3.42  -3.26   -3.2  -3.15  -3.05   4000    1.0
log\_lik[42,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.18  -3.04   4000    1.0
log\_lik[43,0]  -3.64  2.0e-3   0.13  -3.93  -3.71  -3.63  -3.56  -3.42   4000    1.0
log\_lik[44,0]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[45,0]  -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[46,0]  -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[47,0]  -3.06  1.2e-3   0.08  -3.21   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[48,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.18  -3.04   4000    1.0
log\_lik[49,0]  -2.79  8.5e-4   0.05  -2.92  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[50,0]  -3.41  1.7e-3   0.11  -3.66  -3.47   -3.4  -3.34  -3.22   4000    1.0
log\_lik[51,0]  -3.04  1.2e-3   0.08  -3.22  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[52,0]  -3.64  2.0e-3   0.13  -3.93  -3.71  -3.63  -3.56  -3.42   4000    1.0
log\_lik[53,0]  -4.24  2.7e-3   0.17  -4.56  -4.35  -4.24  -4.13  -3.88   4000    1.0
log\_lik[54,0]  -3.06  1.2e-3   0.08  -3.21   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[55,0]  -2.72  7.2e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[56,0]   -2.9  1.0e-3   0.06  -3.05  -2.93  -2.89  -2.86  -2.79   4000    1.0
log\_lik[57,0]  -2.72  7.0e-4   0.04  -2.81  -2.75  -2.72  -2.69  -2.64   4000    1.0
log\_lik[58,0]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64   -2.6   4000    1.0
log\_lik[59,0]  -2.91  9.9e-4   0.06  -3.04  -2.95  -2.92  -2.88  -2.78   4000    1.0
log\_lik[60,0]  -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[61,0]  -2.91  9.9e-4   0.06  -3.04  -2.95  -2.92  -2.88  -2.78   4000    1.0
log\_lik[62,0]  -3.67  2.0e-3   0.13  -3.91  -3.75  -3.67   -3.6  -3.41   4000    1.0
log\_lik[63,0]  -3.44  1.7e-3   0.11  -3.64   -3.5  -3.44  -3.37  -3.21   4000    1.0
log\_lik[64,0]  -2.72  7.2e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[65,0]  -3.21  1.4e-3   0.09  -3.42  -3.26   -3.2  -3.15  -3.05   4000    1.0
log\_lik[66,0]  -3.64  2.0e-3   0.13  -3.93  -3.71  -3.63  -3.56  -3.42   4000    1.0
log\_lik[0,1]   -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[1,1]   -2.67  6.2e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[2,1]   -3.48  1.7e-3   0.11  -3.72  -3.54  -3.47  -3.41  -3.27   4000    1.0
log\_lik[3,1]   -2.68  6.4e-4   0.04  -2.76  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[4,1]   -3.17  1.3e-3   0.08  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[5,1]   -3.17  1.3e-3   0.08  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[6,1]    -2.7  6.8e-4   0.04  -2.79  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[7,1]    -5.2  3.7e-3   0.24  -5.68  -5.35  -5.19  -5.04  -4.74   4000    1.0
log\_lik[8,1]   -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[9,1]   -2.74  7.2e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.65   4000    1.0
log\_lik[10,1]  -2.66  6.0e-4   0.04  -2.73  -2.68  -2.66  -2.63  -2.58   4000    1.0
log\_lik[11,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[12,1]  -3.37  1.6e-3    0.1  -3.57  -3.43  -3.36   -3.3  -3.18   4000    1.0
log\_lik[13,1]  -3.48  1.7e-3   0.11  -3.72  -3.54  -3.47  -3.41  -3.27   4000    1.0
log\_lik[14,1]  -2.82  8.4e-4   0.05  -2.94  -2.85  -2.82  -2.78  -2.73   4000    1.0
log\_lik[15,1]  -3.72  2.0e-3   0.13  -3.99   -3.8  -3.72  -3.63  -3.48   4000    1.0
log\_lik[16,1]  -2.68  6.4e-4   0.04  -2.76  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[17,1]  -3.27  1.5e-3   0.09  -3.47  -3.32  -3.26  -3.21   -3.1   4000    1.0
log\_lik[18,1]  -2.74  7.2e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.65   4000    1.0
log\_lik[19,1]  -3.01  1.1e-3   0.07  -3.16  -3.05  -3.01  -2.96  -2.88   4000    1.0
log\_lik[20,1]  -3.17  1.3e-3   0.08  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[21,1]  -2.88  9.3e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.77   4000    1.0
log\_lik[22,1]  -4.14  2.5e-3   0.16  -4.46  -4.24  -4.14  -4.04  -3.84   4000    1.0
log\_lik[23,1]  -3.09  1.2e-3   0.08  -3.26  -3.13  -3.08  -3.04  -2.95   4000    1.0
log\_lik[24,1]  -2.68  6.4e-4   0.04  -2.76  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[25,1]  -2.88  9.3e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.77   4000    1.0
log\_lik[26,1]  -3.37  1.6e-3    0.1  -3.57  -3.43  -3.36   -3.3  -3.18   4000    1.0
log\_lik[27,1]  -2.67  6.2e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[28,1]  -2.66  6.0e-4   0.04  -2.73  -2.68  -2.66  -2.63  -2.58   4000    1.0
log\_lik[29,1]  -3.09  1.2e-3   0.08  -3.26  -3.13  -3.08  -3.04  -2.95   4000    1.0
log\_lik[30,1]  -3.72  2.0e-3   0.13  -3.99   -3.8  -3.72  -3.63  -3.48   4000    1.0
log\_lik[31,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[32,1]  -4.64  3.2e-3    0.2  -5.05  -4.76  -4.63   -4.5  -4.26   4000    1.0
log\_lik[33,1]  -2.67  6.2e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[34,1]   -2.7  6.8e-4   0.04  -2.79  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[35,1]  -3.17  1.3e-3   0.08  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[36,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[37,1]  -4.46  2.9e-3   0.18  -4.83  -4.58  -4.46  -4.34  -4.11   4000    1.0
log\_lik[38,1]  -3.72  2.0e-3   0.13  -3.99   -3.8  -3.72  -3.63  -3.48   4000    1.0
log\_lik[39,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[40,1]   -2.7  6.8e-4   0.04  -2.79  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[41,1]  -3.48  1.7e-3   0.11  -3.72  -3.54  -3.47  -3.41  -3.27   4000    1.0
log\_lik[42,1]  -3.72  2.0e-3   0.13  -3.99   -3.8  -3.72  -3.63  -3.48   4000    1.0
log\_lik[43,1]  -3.09  1.2e-3   0.08  -3.26  -3.13  -3.08  -3.04  -2.95   4000    1.0
log\_lik[44,1]  -2.66  6.0e-4   0.04  -2.73  -2.68  -2.66  -2.63  -2.58   4000    1.0
log\_lik[45,1]  -3.72  2.0e-3   0.13  -3.99   -3.8  -3.72  -3.63  -3.48   4000    1.0
log\_lik[46,1]  -2.68  6.4e-4   0.04  -2.76  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[47,1]  -3.27  1.5e-3   0.09  -3.47  -3.32  -3.26  -3.21   -3.1   4000    1.0
log\_lik[48,1]  -2.94  1.0e-3   0.06  -3.08  -2.98  -2.94  -2.89  -2.82   4000    1.0
log\_lik[49,1]  -2.88  9.3e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.77   4000    1.0
log\_lik[50,1]  -4.46  2.9e-3   0.18  -4.83  -4.58  -4.46  -4.34  -4.11   4000    1.0
log\_lik[51,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[52,1]  -3.59  1.8e-3   0.12  -3.83  -3.67  -3.59  -3.52  -3.37   4000    1.0
log\_lik[53,1]  -2.94  1.0e-3   0.06  -3.08  -2.98  -2.94  -2.89  -2.82   4000    1.0
log\_lik[54,1]  -2.67  6.2e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[55,1]  -3.72  2.0e-3   0.13  -3.99   -3.8  -3.72  -3.63  -3.48   4000    1.0
log\_lik[56,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[57,1]  -2.82  8.4e-4   0.05  -2.94  -2.85  -2.82  -2.78  -2.73   4000    1.0
log\_lik[58,1]  -3.59  1.8e-3   0.12  -3.83  -3.67  -3.59  -3.52  -3.37   4000    1.0
log\_lik[59,1]  -2.88  9.3e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.77   4000    1.0
log\_lik[60,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[61,1]  -2.68  6.4e-4   0.04  -2.76  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[62,1]   -4.3  2.8e-3   0.17  -4.66  -4.41  -4.29  -4.18  -3.98   4000    1.0
log\_lik[63,1]  -2.94  1.0e-3   0.06  -3.08  -2.98  -2.94  -2.89  -2.82   4000    1.0
log\_lik[64,1]  -2.88  9.3e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.77   4000    1.0
log\_lik[65,1]  -3.17  1.3e-3   0.08  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[66,1]  -2.77  7.9e-4   0.05  -2.88  -2.81  -2.77  -2.74  -2.68   4000    1.0
log\_lik[0,2]   -2.72  7.1e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[1,2]   -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[2,2]   -4.24  2.7e-3   0.17  -4.58  -4.35  -4.23  -4.13   -3.9   4000    1.0
log\_lik[3,2]   -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[4,2]   -3.21  1.4e-3   0.09  -3.41  -3.26   -3.2  -3.15  -3.05   4000    1.0
log\_lik[5,2]   -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[6,2]   -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[7,2]   -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[8,2]   -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[9,2]   -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[10,2]  -3.94  2.3e-3   0.15  -4.24  -4.04  -3.94  -3.85  -3.65   4000    1.0
log\_lik[11,2]  -2.72  7.1e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[12,2]  -2.72  7.1e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[13,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[14,2]  -2.72  7.1e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[15,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.42   4000    1.0
log\_lik[16,2]   -2.8  8.3e-4   0.05  -2.91  -2.84   -2.8  -2.77   -2.7   4000    1.0
log\_lik[17,2]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01  -2.91   4000    1.0
log\_lik[18,2]  -2.91  9.9e-4   0.06  -3.04  -2.96  -2.92  -2.87  -2.79   4000    1.0
log\_lik[19,2]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[20,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[21,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[22,2]  -3.64  2.0e-3   0.13  -3.91  -3.72  -3.63  -3.56  -3.43   4000    1.0
log\_lik[23,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[24,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[25,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[26,2]  -3.64  2.0e-3   0.13  -3.91  -3.72  -3.63  -3.56  -3.43   4000    1.0
log\_lik[27,2]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[28,2]  -3.91  2.3e-3   0.15  -4.22  -3.99  -3.89  -3.81  -3.65   4000    1.0
log\_lik[29,2]  -3.04  1.2e-3   0.08  -3.21  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[30,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.42   4000    1.0
log\_lik[31,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[32,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[33,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.42   4000    1.0
log\_lik[34,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[35,2]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[36,2]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[37,2]  -4.88  3.5e-3   0.22  -5.36  -5.02  -4.87  -4.73  -4.49   4000    1.0
log\_lik[38,2]  -2.67  6.2e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[39,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[40,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[41,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[42,2]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[43,2]  -2.67  6.3e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[44,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.42   4000    1.0
log\_lik[45,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.42   4000    1.0
log\_lik[46,2]  -2.91  9.9e-4   0.06  -3.04  -2.96  -2.92  -2.87  -2.79   4000    1.0
log\_lik[47,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[48,2]   -2.8  8.3e-4   0.05  -2.91  -2.84   -2.8  -2.77   -2.7   4000    1.0
log\_lik[49,2]  -3.91  2.3e-3   0.15  -4.22  -3.99  -3.89  -3.81  -3.65   4000    1.0
log\_lik[50,2]  -3.21  1.4e-3   0.09  -3.41  -3.26   -3.2  -3.15  -3.05   4000    1.0
log\_lik[51,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[52,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.42   4000    1.0
log\_lik[53,2]  -2.91  9.9e-4   0.06  -3.04  -2.96  -2.92  -2.87  -2.79   4000    1.0
log\_lik[54,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[55,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[56,2]  -2.72  7.1e-4   0.05  -2.81  -2.74  -2.71  -2.69  -2.63   4000    1.0
log\_lik[57,2]   -4.2  2.7e-3   0.17  -4.57  -4.31  -4.18  -4.09  -3.91   4000    1.0
log\_lik[58,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[59,2]  -2.79  8.4e-4   0.05  -2.91  -2.82  -2.79  -2.76   -2.7   4000    1.0
log\_lik[60,2]  -2.72  7.0e-4   0.04  -2.81  -2.75  -2.72  -2.69  -2.64   4000    1.0
log\_lik[61,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[62,2]  -2.67  6.2e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[63,2]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[64,2]  -2.66  6.0e-4   0.04  -2.73  -2.68  -2.66  -2.63  -2.58   4000    1.0
log\_lik[65,2]  -2.67  6.2e-4   0.04  -2.75   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[66,2]  -3.94  2.3e-3   0.15  -4.24  -4.04  -3.94  -3.85  -3.65   4000    1.0
log\_lik[0,3]   -3.76  2.2e-3   0.14  -4.09  -3.84  -3.75  -3.66  -3.53   4000    1.0
log\_lik[1,3]   -2.69  6.7e-4   0.04  -2.78  -2.72  -2.69  -2.66  -2.61   4000    1.0
log\_lik[2,3]   -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[3,3]   -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[4,3]   -2.66  6.1e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[5,3]   -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[6,3]   -4.09  2.5e-3   0.16   -4.4   -4.2   -4.1  -3.99  -3.77   4000    1.0
log\_lik[7,3]   -4.76  3.3e-3   0.21  -5.16   -4.9  -4.76  -4.62  -4.34   4000    1.0
log\_lik[8,3]   -2.96  1.1e-3   0.07  -3.13   -3.0  -2.95  -2.91  -2.85   4000    1.0
log\_lik[9,3]   -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[10,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[11,3]   -2.7  6.7e-4   0.04  -2.78  -2.72   -2.7  -2.67  -2.61   4000    1.0
log\_lik[12,3]  -4.04  2.6e-3   0.16  -4.41  -4.13  -4.02  -3.93  -3.77   4000    1.0
log\_lik[13,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[14,3]  -3.76  2.2e-3   0.14  -4.09  -3.84  -3.75  -3.66  -3.53   4000    1.0
log\_lik[15,3]  -2.66  6.1e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[16,3]  -3.11  1.4e-3   0.09  -3.31  -3.16   -3.1  -3.05  -2.98   4000    1.0
log\_lik[17,3]  -4.35  3.0e-3   0.19  -4.77  -4.46  -4.33  -4.22  -4.03   4000    1.0
log\_lik[18,3]  -2.96  1.1e-3   0.07  -3.13   -3.0  -2.95  -2.91  -2.85   4000    1.0
log\_lik[19,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[20,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[21,3]  -2.66  6.1e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[22,3]  -3.56  1.9e-3   0.12  -3.78  -3.64  -3.56  -3.48  -3.31   4000    1.0
log\_lik[23,3]   -2.7  6.7e-4   0.04  -2.78  -2.72   -2.7  -2.67  -2.61   4000    1.0
log\_lik[24,3]  -3.34  1.6e-3    0.1  -3.52   -3.4  -3.34  -3.27  -3.13   4000    1.0
log\_lik[25,3]  -2.96  1.1e-3   0.07  -3.13   -3.0  -2.95  -2.91  -2.85   4000    1.0
log\_lik[26,3]  -3.56  1.9e-3   0.12  -3.78  -3.64  -3.56  -3.48  -3.31   4000    1.0
log\_lik[27,3]  -2.99  1.1e-3   0.07  -3.12  -3.03  -2.99  -2.94  -2.84   4000    1.0
log\_lik[28,3]  -3.34  1.6e-3    0.1  -3.52   -3.4  -3.34  -3.27  -3.13   4000    1.0
log\_lik[29,3]  -2.66  6.1e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[30,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[31,3]   -2.7  6.7e-4   0.04  -2.78  -2.72   -2.7  -2.67  -2.61   4000    1.0
log\_lik[32,3]   -3.3  1.6e-3    0.1  -3.53  -3.35  -3.29  -3.23  -3.13   4000    1.0
log\_lik[33,3]  -2.96  1.1e-3   0.07  -3.13   -3.0  -2.95  -2.91  -2.85   4000    1.0
log\_lik[34,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[35,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[36,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[37,3]  -5.13  3.8e-3   0.24   -5.6   -5.3  -5.14  -4.98  -4.67   4000    1.0
log\_lik[38,3]  -3.76  2.2e-3   0.14  -4.09  -3.84  -3.75  -3.66  -3.53   4000    1.0
log\_lik[39,3]  -2.84  9.4e-4   0.06  -2.98  -2.87  -2.83   -2.8  -2.74   4000    1.0
log\_lik[40,3]  -3.11  1.4e-3   0.09  -3.31  -3.16   -3.1  -3.05  -2.98   4000    1.0
log\_lik[41,3]  -2.96  1.1e-3   0.07  -3.13   -3.0  -2.95  -2.91  -2.85   4000    1.0
log\_lik[42,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[43,3]  -4.76  3.3e-3   0.21  -5.16   -4.9  -4.76  -4.62  -4.34   4000    1.0
log\_lik[44,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[45,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[46,3]  -2.75  7.8e-4   0.05  -2.86  -2.78  -2.74  -2.71  -2.66   4000    1.0
log\_lik[47,3]  -2.84  9.4e-4   0.06  -2.98  -2.87  -2.83   -2.8  -2.74   4000    1.0
log\_lik[48,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[49,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[50,3]   -3.3  1.6e-3    0.1  -3.53  -3.35  -3.29  -3.23  -3.13   4000    1.0
log\_lik[51,3]   -2.7  6.7e-4   0.04  -2.78  -2.72   -2.7  -2.67  -2.61   4000    1.0
log\_lik[52,3]   -3.3  1.6e-3    0.1  -3.53  -3.35  -3.29  -3.23  -3.13   4000    1.0
log\_lik[53,3]  -3.76  2.2e-3   0.14  -4.09  -3.84  -3.75  -3.66  -3.53   4000    1.0
log\_lik[54,3]  -2.84  9.4e-4   0.06  -2.98  -2.87  -2.83   -2.8  -2.74   4000    1.0
log\_lik[55,3]  -4.69  3.4e-3   0.22  -5.18  -4.82  -4.67  -4.54  -4.32   4000    1.0
log\_lik[56,3]   -3.3  1.6e-3    0.1  -3.53  -3.35  -3.29  -3.23  -3.13   4000    1.0
log\_lik[57,3]  -3.34  1.6e-3    0.1  -3.52   -3.4  -3.34  -3.27  -3.13   4000    1.0
log\_lik[58,3]  -4.09  2.5e-3   0.16   -4.4   -4.2   -4.1  -3.99  -3.77   4000    1.0
log\_lik[59,3]  -3.56  1.9e-3   0.12  -3.78  -3.64  -3.56  -3.48  -3.31   4000    1.0
log\_lik[60,3]  -3.56  1.9e-3   0.12  -3.78  -3.64  -3.56  -3.48  -3.31   4000    1.0
log\_lik[61,3]  -2.84  9.4e-4   0.06  -2.98  -2.87  -2.83   -2.8  -2.74   4000    1.0
log\_lik[62,3]  -2.76  7.8e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[63,3]  -2.66  6.1e-4   0.04  -2.74  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[64,3]  -3.56  1.9e-3   0.12  -3.78  -3.64  -3.56  -3.48  -3.31   4000    1.0
log\_lik[65,3]  -3.76  2.2e-3   0.14  -4.09  -3.84  -3.75  -3.66  -3.53   4000    1.0
log\_lik[66,3]  -3.56  1.9e-3   0.12  -3.78  -3.64  -3.56  -3.48  -3.31   4000    1.0
log\_lik[0,4]   -5.37  4.1e-3   0.26   -5.9  -5.54  -5.37   -5.2  -4.88   4000    1.0
log\_lik[1,4]   -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[2,4]   -3.98  2.4e-3   0.15  -4.28  -4.07  -3.97  -3.88  -3.69   4000    1.0
log\_lik[3,4]   -2.68  6.3e-4   0.04  -2.76   -2.7  -2.68  -2.65   -2.6   4000    1.0
log\_lik[4,4]   -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[5,4]   -3.18  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[6,4]   -3.18  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[7,4]   -3.87  2.2e-3   0.14  -4.17  -3.95  -3.86  -3.78  -3.61   4000    1.0
log\_lik[8,4]   -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[9,4]   -2.88  9.6e-4   0.06  -3.02  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[10,4]  -2.67  6.2e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[11,4]  -4.28  2.7e-3   0.17  -4.64  -4.39  -4.27  -4.16  -3.94   4000    1.0
log\_lik[12,4]  -2.82  8.4e-4   0.05  -2.93  -2.85  -2.81  -2.78  -2.71   4000    1.0
log\_lik[13,4]  -3.25  1.4e-3   0.09  -3.44  -3.31  -3.25   -3.2  -3.08   4000    1.0
log\_lik[14,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[15,4]  -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[16,4]  -3.18  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[17,4]  -3.18  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[18,4]  -5.22  3.8e-3   0.24  -5.73  -5.37  -5.22  -5.06  -4.76   4000    1.0
log\_lik[19,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[20,4]  -2.68  6.3e-4   0.04  -2.76   -2.7  -2.68  -2.65   -2.6   4000    1.0
log\_lik[21,4]  -2.67  6.2e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[22,4]  -2.82  8.4e-4   0.05  -2.93  -2.85  -2.81  -2.78  -2.71   4000    1.0
log\_lik[23,4]  -2.73  7.2e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.65   4000    1.0
log\_lik[24,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[25,4]  -2.68  6.3e-4   0.04  -2.76   -2.7  -2.68  -2.65   -2.6   4000    1.0
log\_lik[26,4]  -4.61  3.1e-3    0.2  -5.03  -4.74  -4.61  -4.48  -4.23   4000    1.0
log\_lik[27,4]   -3.7  2.0e-3   0.13  -3.97  -3.78   -3.7  -3.62  -3.46   4000    1.0
log\_lik[28,4]  -3.08  1.2e-3   0.08  -3.24  -3.12  -3.07  -3.03  -2.93   4000    1.0
log\_lik[29,4]  -2.67  6.2e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[30,4]  -3.61  1.9e-3   0.12  -3.87  -3.68   -3.6  -3.54  -3.39   4000    1.0
log\_lik[31,4]  -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[32,4]  -2.88  9.6e-4   0.06  -3.02  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[33,4]  -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[34,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[35,4]  -4.28  2.7e-3   0.17  -4.64  -4.39  -4.27  -4.16  -3.94   4000    1.0
log\_lik[36,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[37,4]  -2.68  6.3e-4   0.04  -2.76   -2.7  -2.68  -2.65   -2.6   4000    1.0
log\_lik[38,4]  -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[39,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[40,4]  -2.88  9.6e-4   0.06  -3.02  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[41,4]   -3.7  2.0e-3   0.13  -3.97  -3.78   -3.7  -3.62  -3.46   4000    1.0
log\_lik[42,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[43,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[44,4]  -3.25  1.4e-3   0.09  -3.44  -3.31  -3.25   -3.2  -3.08   4000    1.0
log\_lik[45,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[46,4]  -3.61  1.9e-3   0.12  -3.87  -3.68   -3.6  -3.54  -3.39   4000    1.0
log\_lik[47,4]  -2.88  9.6e-4   0.06  -3.02  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[48,4]  -3.61  1.9e-3   0.12  -3.87  -3.68   -3.6  -3.54  -3.39   4000    1.0
log\_lik[49,4]   -3.7  2.0e-3   0.13  -3.97  -3.78   -3.7  -3.62  -3.46   4000    1.0
log\_lik[50,4]  -2.67  6.2e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[51,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[52,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[53,4]   -3.7  2.0e-3   0.13  -3.97  -3.78   -3.7  -3.62  -3.46   4000    1.0
log\_lik[54,4]  -2.66  6.0e-4   0.04  -2.73  -2.68  -2.66  -2.63  -2.58   4000    1.0
log\_lik[55,4]  -2.82  8.4e-4   0.05  -2.93  -2.85  -2.81  -2.78  -2.71   4000    1.0
log\_lik[56,4]  -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[57,4]  -2.73  7.2e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.65   4000    1.0
log\_lik[58,4]  -3.25  1.4e-3   0.09  -3.44  -3.31  -3.25   -3.2  -3.08   4000    1.0
log\_lik[59,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[60,4]  -2.78  8.0e-4   0.05  -2.89  -2.81  -2.78  -2.75  -2.69   4000    1.0
log\_lik[61,4]  -4.84  3.4e-3   0.21  -5.29  -4.97  -4.83   -4.7  -4.44   4000    1.0
log\_lik[62,4]  -3.38  1.6e-3    0.1  -3.61  -3.44  -3.38  -3.32  -3.19   4000    1.0
log\_lik[63,4]  -3.61  1.9e-3   0.12  -3.87  -3.68   -3.6  -3.54  -3.39   4000    1.0
log\_lik[64,4]  -2.71  6.9e-4   0.04   -2.8  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[65,4]  -2.82  8.4e-4   0.05  -2.93  -2.85  -2.81  -2.78  -2.71   4000    1.0
log\_lik[66,4]  -3.46  1.7e-3   0.11  -3.69  -3.53  -3.46  -3.39  -3.26   4000    1.0
ypred[0]       14.17    0.09   5.63   2.93  10.34  14.11  17.91   25.5   3712    1.0
ypred[1]       14.32    0.09   5.72   2.96  10.46  14.23  18.35  25.13   3657    1.0
ypred[2]       14.22    0.09   5.69   2.71  10.53  14.23  18.08  25.33   4000    1.0
ypred[3]       14.41    0.09   5.78   2.92  10.63  14.34  18.28  25.82   3825    1.0
ypred[4]        14.2    0.09   5.64   3.06  10.31  14.24  18.04  24.89   4000    1.0
mu\_new         14.22    0.02   0.94  12.45  13.86  14.21  14.57  16.09   2731    1.0
ypred\_new       14.2    0.09    5.8   2.84  10.26  14.19  18.17  25.49   4000    1.0
lp\_\_          -749.3    0.07   2.27 -754.3 -750.6 -749.1 -747.7 -745.4   1146    1.0

Samples were drawn using NUTS at Sun Dec  9 13:48:51 2018.
For each parameter, n\_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).

\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\#\#\#\# Attachment 4: Fit of hierarchical model with inverse gamma prior \#\#\#\#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

Inference for Stan model: anon\_model\_48a5c6bedf159373816b9432a8388eb4.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

                mean se\_mean     sd   2.5\%    25\%    50\%    75\%  97.5\%  n\_eff   Rhat
mu0            14.17    0.01   0.43  13.33  13.91  14.18  14.45   15.0   1637    1.0
sigma0          0.55    0.02   0.57   0.02   0.19    0.4   0.73   2.04    913    1.0
mu\_tilde[0]     -0.2    0.02   0.88  -1.96  -0.76  -0.21   0.37   1.56   3191    1.0
mu\_tilde[1]     0.12    0.02   0.88  -1.68  -0.43    0.1    0.7   1.83   2959    1.0
mu\_tilde[2]     -0.2    0.01   0.86  -1.94  -0.75  -0.22   0.35   1.49   3433    1.0
mu\_tilde[3]     0.37    0.02   0.85  -1.42  -0.16   0.38   0.93   2.05   3213    1.0
mu\_tilde[4]   3.1e-3    0.01   0.84  -1.68  -0.54-1.8e-3   0.53   1.75   3325    1.0
sigmaSq        31.97    0.04   2.56  27.37   30.2  31.81  33.63  37.32   4000    1.0
mu[0]          14.06  7.7e-3   0.48  13.02  13.77  14.09  14.39  14.96   4000    1.0
mu[1]          14.25  7.5e-3   0.47  13.32  13.96  14.24  14.55  15.22   4000    1.0
mu[2]          14.05  7.7e-3   0.49   13.0  13.75  14.08  14.36  14.94   4000    1.0
mu[3]          14.41  7.8e-3   0.49  13.54  14.06  14.38  14.71  15.49   4000    1.0
mu[4]          14.18  7.4e-3   0.47  13.23   13.9  14.19  14.49   15.1   4000    1.0
sigma           5.65  3.6e-3   0.23   5.23    5.5   5.64    5.8   6.11   4000    1.0
log\_lik[0,0]   -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[1,0]   -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[2,0]   -2.71  7.3e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[3,0]   -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[4,0]   -3.04  1.2e-3   0.08  -3.21  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[5,0]   -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[6,0]   -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[7,0]   -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[8,0]   -3.95  2.4e-3   0.15  -4.24  -4.04  -3.95  -3.85  -3.64   4000    1.0
log\_lik[9,0]   -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[10,0]  -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[11,0]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01   -2.9   4000    1.0
log\_lik[12,0]  -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[13,0]  -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[14,0]  -3.95  2.4e-3   0.15  -4.24  -4.04  -3.95  -3.85  -3.64   4000    1.0
log\_lik[15,0]  -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[16,0]   -2.8  8.6e-4   0.05  -2.91  -2.84   -2.8  -2.76   -2.7   4000    1.0
log\_lik[17,0]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01   -2.9   4000    1.0
log\_lik[18,0]  -2.71  7.3e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[19,0]  -3.41  1.7e-3   0.11  -3.65  -3.47   -3.4  -3.34  -3.22   4000    1.0
log\_lik[20,0]  -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[21,0]  -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[22,0]  -4.21  2.8e-3   0.18   -4.6  -4.32  -4.19  -4.09  -3.89   4000    1.0
log\_lik[23,0]  -2.91  1.0e-3   0.06  -3.04  -2.96  -2.91  -2.87  -2.79   4000    1.0
log\_lik[24,0]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01   -2.9   4000    1.0
log\_lik[25,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[26,0]  -3.65  2.0e-3   0.13  -3.93  -3.72  -3.63  -3.56  -3.42   4000    1.0
log\_lik[27,0]  -2.72  7.4e-4   0.05  -2.81  -2.75  -2.72  -2.69  -2.63   4000    1.0
log\_lik[28,0]  -3.04  1.2e-3   0.08  -3.21  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[29,0]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01   -2.9   4000    1.0
log\_lik[30,0]  -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[31,0]  -2.72  7.4e-4   0.05  -2.81  -2.75  -2.72  -2.69  -2.63   4000    1.0
log\_lik[32,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[33,0]  -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[34,0]  -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[35,0]  -4.54  3.2e-3    0.2  -4.98  -4.66  -4.52  -4.39  -4.18   4000    1.0
log\_lik[36,0]  -3.04  1.2e-3   0.08  -3.21  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[37,0]  -4.21  2.8e-3   0.18   -4.6  -4.32  -4.19  -4.09  -3.89   4000    1.0
log\_lik[38,0]  -2.71  7.3e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[39,0]  -3.95  2.4e-3   0.15  -4.24  -4.04  -3.95  -3.85  -3.64   4000    1.0
log\_lik[40,0]  -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[41,0]  -3.21  1.5e-3   0.09  -3.41  -3.26   -3.2  -3.15  -3.05   4000    1.0
log\_lik[42,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[43,0]  -3.65  2.0e-3   0.13  -3.93  -3.72  -3.63  -3.56  -3.42   4000    1.0
log\_lik[44,0]  -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[45,0]  -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[46,0]  -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[47,0]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01   -2.9   4000    1.0
log\_lik[48,0]  -3.23  1.4e-3   0.09  -3.41  -3.29  -3.23  -3.17  -3.05   4000    1.0
log\_lik[49,0]  -2.79  8.5e-4   0.05  -2.91  -2.82  -2.79  -2.75  -2.69   4000    1.0
log\_lik[50,0]  -3.41  1.7e-3   0.11  -3.65  -3.47   -3.4  -3.34  -3.22   4000    1.0
log\_lik[51,0]  -3.04  1.2e-3   0.08  -3.21  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[52,0]  -3.65  2.0e-3   0.13  -3.93  -3.72  -3.63  -3.56  -3.42   4000    1.0
log\_lik[53,0]  -4.25  2.7e-3   0.17  -4.59  -4.36  -4.25  -4.13   -3.9   4000    1.0
log\_lik[54,0]  -3.06  1.2e-3   0.08  -3.21  -3.11  -3.06  -3.01   -2.9   4000    1.0
log\_lik[55,0]  -2.71  7.3e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[56,0]   -2.9  1.0e-3   0.06  -3.04  -2.93  -2.89  -2.86  -2.79   4000    1.0
log\_lik[57,0]  -2.72  7.4e-4   0.05  -2.81  -2.75  -2.72  -2.69  -2.63   4000    1.0
log\_lik[58,0]  -2.67  6.6e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[59,0]  -2.91  1.0e-3   0.06  -3.04  -2.96  -2.91  -2.87  -2.79   4000    1.0
log\_lik[60,0]  -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[61,0]  -2.91  1.0e-3   0.06  -3.04  -2.96  -2.91  -2.87  -2.79   4000    1.0
log\_lik[62,0]  -3.68  2.0e-3   0.13  -3.93  -3.76  -3.68  -3.59  -3.42   4000    1.0
log\_lik[63,0]  -3.44  1.7e-3   0.11  -3.65  -3.51  -3.44  -3.37  -3.22   4000    1.0
log\_lik[64,0]  -2.71  7.3e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[65,0]  -3.21  1.5e-3   0.09  -3.41  -3.26   -3.2  -3.15  -3.05   4000    1.0
log\_lik[66,0]  -3.65  2.0e-3   0.13  -3.93  -3.72  -3.63  -3.56  -3.42   4000    1.0
log\_lik[0,1]   -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[1,1]   -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[2,1]   -3.48  1.8e-3   0.11  -3.72  -3.55  -3.47  -3.41  -3.27   4000    1.0
log\_lik[3,1]   -2.68  6.8e-4   0.04  -2.77  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[4,1]   -3.17  1.3e-3   0.09  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[5,1]   -3.17  1.3e-3   0.09  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[6,1]    -2.7  7.0e-4   0.04  -2.79  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[7,1]   -5.21  4.0e-3   0.25  -5.73  -5.38   -5.2  -5.04  -4.73   4000    1.0
log\_lik[8,1]   -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[9,1]   -2.73  7.7e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.64   4000    1.0
log\_lik[10,1]  -2.65  6.4e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   4000    1.0
log\_lik[11,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[12,1]  -3.37  1.6e-3    0.1  -3.59  -3.43  -3.37   -3.3  -3.17   4000    1.0
log\_lik[13,1]  -3.48  1.8e-3   0.11  -3.72  -3.55  -3.47  -3.41  -3.27   4000    1.0
log\_lik[14,1]  -2.82  8.9e-4   0.06  -2.94  -2.85  -2.82  -2.78  -2.72   4000    1.0
log\_lik[15,1]  -3.73  2.1e-3   0.13  -4.01   -3.8  -3.72  -3.64  -3.49   4000    1.0
log\_lik[16,1]  -2.68  6.8e-4   0.04  -2.77  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[17,1]  -3.27  1.5e-3   0.09  -3.48  -3.32  -3.26  -3.21   -3.1   4000    1.0
log\_lik[18,1]  -2.73  7.7e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.64   4000    1.0
log\_lik[19,1]  -3.01  1.1e-3   0.07  -3.16  -3.05  -3.01  -2.96  -2.87   4000    1.0
log\_lik[20,1]  -3.17  1.3e-3   0.09  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[21,1]  -2.87  9.4e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.76   4000    1.0
log\_lik[22,1]  -4.15  2.6e-3   0.17  -4.49  -4.25  -4.14  -4.04  -3.83   4000    1.0
log\_lik[23,1]  -3.09  1.3e-3   0.08  -3.26  -3.13  -3.08  -3.04  -2.94   4000    1.0
log\_lik[24,1]  -2.68  6.8e-4   0.04  -2.77  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[25,1]  -2.87  9.4e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.76   4000    1.0
log\_lik[26,1]  -3.37  1.6e-3    0.1  -3.59  -3.43  -3.37   -3.3  -3.17   4000    1.0
log\_lik[27,1]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[28,1]  -2.65  6.4e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   4000    1.0
log\_lik[29,1]  -3.09  1.3e-3   0.08  -3.26  -3.13  -3.08  -3.04  -2.94   4000    1.0
log\_lik[30,1]  -3.73  2.1e-3   0.13  -4.01   -3.8  -3.72  -3.64  -3.49   4000    1.0
log\_lik[31,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[32,1]  -4.65  3.2e-3    0.2  -5.07  -4.77  -4.64  -4.51  -4.27   4000    1.0
log\_lik[33,1]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[34,1]   -2.7  7.0e-4   0.04  -2.79  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[35,1]  -3.17  1.3e-3   0.09  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[36,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[37,1]  -4.47  3.1e-3   0.19  -4.87  -4.59  -4.47  -4.34   -4.1   4000    1.0
log\_lik[38,1]  -3.73  2.1e-3   0.13  -4.01   -3.8  -3.72  -3.64  -3.49   4000    1.0
log\_lik[39,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[40,1]   -2.7  7.0e-4   0.04  -2.79  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[41,1]  -3.48  1.8e-3   0.11  -3.72  -3.55  -3.47  -3.41  -3.27   4000    1.0
log\_lik[42,1]  -3.73  2.1e-3   0.13  -4.01   -3.8  -3.72  -3.64  -3.49   4000    1.0
log\_lik[43,1]  -3.09  1.3e-3   0.08  -3.26  -3.13  -3.08  -3.04  -2.94   4000    1.0
log\_lik[44,1]  -2.65  6.4e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   4000    1.0
log\_lik[45,1]  -3.73  2.1e-3   0.13  -4.01   -3.8  -3.72  -3.64  -3.49   4000    1.0
log\_lik[46,1]  -2.68  6.8e-4   0.04  -2.77  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[47,1]  -3.27  1.5e-3   0.09  -3.48  -3.32  -3.26  -3.21   -3.1   4000    1.0
log\_lik[48,1]  -2.94  1.1e-3   0.07  -3.08  -2.98  -2.93  -2.89  -2.82   4000    1.0
log\_lik[49,1]  -2.87  9.4e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.76   4000    1.0
log\_lik[50,1]  -4.47  3.1e-3   0.19  -4.87  -4.59  -4.47  -4.34   -4.1   4000    1.0
log\_lik[51,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[52,1]   -3.6  1.9e-3   0.12  -3.85  -3.67   -3.6  -3.52  -3.36   4000    1.0
log\_lik[53,1]  -2.94  1.1e-3   0.07  -3.08  -2.98  -2.93  -2.89  -2.82   4000    1.0
log\_lik[54,1]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[55,1]  -3.73  2.1e-3   0.13  -4.01   -3.8  -3.72  -3.64  -3.49   4000    1.0
log\_lik[56,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[57,1]  -2.82  8.9e-4   0.06  -2.94  -2.85  -2.82  -2.78  -2.72   4000    1.0
log\_lik[58,1]   -3.6  1.9e-3   0.12  -3.85  -3.67   -3.6  -3.52  -3.36   4000    1.0
log\_lik[59,1]  -2.87  9.4e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.76   4000    1.0
log\_lik[60,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[61,1]  -2.68  6.8e-4   0.04  -2.77  -2.71  -2.68  -2.65   -2.6   4000    1.0
log\_lik[62,1]  -4.31  2.8e-3   0.18  -4.68  -4.42   -4.3  -4.19  -3.98   4000    1.0
log\_lik[63,1]  -2.94  1.1e-3   0.07  -3.08  -2.98  -2.93  -2.89  -2.82   4000    1.0
log\_lik[64,1]  -2.87  9.4e-4   0.06   -3.0  -2.91  -2.87  -2.84  -2.76   4000    1.0
log\_lik[65,1]  -3.17  1.3e-3   0.09  -3.35  -3.23  -3.17  -3.12  -3.01   4000    1.0
log\_lik[66,1]  -2.77  7.9e-4   0.05  -2.88   -2.8  -2.77  -2.74  -2.68   4000    1.0
log\_lik[0,2]   -2.71  7.5e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[1,2]   -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[2,2]   -4.24  2.8e-3   0.17  -4.58  -4.36  -4.24  -4.13   -3.9   4000    1.0
log\_lik[3,2]   -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[4,2]   -3.21  1.5e-3   0.09  -3.42  -3.26   -3.2  -3.15  -3.06   4000    1.0
log\_lik[5,2]   -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[6,2]   -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[7,2]   -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[8,2]   -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[9,2]   -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[10,2]  -3.94  2.4e-3   0.15  -4.24  -4.04  -3.94  -3.84  -3.65   4000    1.0
log\_lik[11,2]  -2.71  7.5e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[12,2]  -2.71  7.5e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[13,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[14,2]  -2.71  7.5e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[15,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.41   4000    1.0
log\_lik[16,2]   -2.8  8.5e-4   0.05  -2.91  -2.83   -2.8  -2.76  -2.69   4000    1.0
log\_lik[17,2]  -3.05  1.2e-3   0.08   -3.2   -3.1  -3.06  -3.01   -2.9   4000    1.0
log\_lik[18,2]  -2.91  1.0e-3   0.06  -3.04  -2.95  -2.91  -2.87  -2.78   4000    1.0
log\_lik[19,2]  -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[20,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[21,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[22,2]  -3.65  2.1e-3   0.13  -3.95  -3.72  -3.64  -3.56  -3.42   4000    1.0
log\_lik[23,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[24,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[25,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[26,2]  -3.65  2.1e-3   0.13  -3.95  -3.72  -3.64  -3.56  -3.42   4000    1.0
log\_lik[27,2]  -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[28,2]  -3.92  2.4e-3   0.15  -4.26   -4.0   -3.9  -3.81  -3.65   4000    1.0
log\_lik[29,2]  -3.04  1.2e-3   0.08  -3.22  -3.08  -3.03  -2.99  -2.91   4000    1.0
log\_lik[30,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.41   4000    1.0
log\_lik[31,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[32,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[33,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.41   4000    1.0
log\_lik[34,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[35,2]  -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[36,2]  -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[37,2]   -4.9  3.7e-3   0.23  -5.42  -5.04  -4.88  -4.74  -4.49   4000    1.0
log\_lik[38,2]  -2.67  6.6e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[39,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[40,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[41,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[42,2]  -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[43,2]  -2.67  6.7e-4   0.04  -2.75  -2.69  -2.67  -2.64  -2.59   4000    1.0
log\_lik[44,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.41   4000    1.0
log\_lik[45,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.41   4000    1.0
log\_lik[46,2]  -2.91  1.0e-3   0.06  -3.04  -2.95  -2.91  -2.87  -2.78   4000    1.0
log\_lik[47,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[48,2]   -2.8  8.5e-4   0.05  -2.91  -2.83   -2.8  -2.76  -2.69   4000    1.0
log\_lik[49,2]  -3.92  2.4e-3   0.15  -4.26   -4.0   -3.9  -3.81  -3.65   4000    1.0
log\_lik[50,2]  -3.21  1.5e-3   0.09  -3.42  -3.26   -3.2  -3.15  -3.06   4000    1.0
log\_lik[51,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[52,2]  -3.67  2.0e-3   0.13  -3.92  -3.75  -3.67  -3.59  -3.41   4000    1.0
log\_lik[53,2]  -2.91  1.0e-3   0.06  -3.04  -2.95  -2.91  -2.87  -2.78   4000    1.0
log\_lik[54,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[55,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[56,2]  -2.71  7.5e-4   0.05  -2.81  -2.74  -2.71  -2.68  -2.63   4000    1.0
log\_lik[57,2]  -4.21  2.8e-3   0.18  -4.61  -4.32   -4.2  -4.09  -3.91   4000    1.0
log\_lik[58,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[59,2]  -2.79  8.7e-4   0.05  -2.91  -2.82  -2.79  -2.75   -2.7   4000    1.0
log\_lik[60,2]  -2.72  7.3e-4   0.05  -2.81  -2.75  -2.72  -2.69  -2.63   4000    1.0
log\_lik[61,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[62,2]  -2.67  6.6e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[63,2]  -3.23  1.4e-3   0.09   -3.4  -3.29  -3.23  -3.17  -3.04   4000    1.0
log\_lik[64,2]  -2.65  6.4e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   4000    1.0
log\_lik[65,2]  -2.67  6.6e-4   0.04  -2.75   -2.7  -2.67  -2.64  -2.59   4000    1.0
log\_lik[66,2]  -3.94  2.4e-3   0.15  -4.24  -4.04  -3.94  -3.84  -3.65   4000    1.0
log\_lik[0,3]   -3.77  2.3e-3   0.14  -4.09  -3.85  -3.75  -3.67  -3.53   4000    1.0
log\_lik[1,3]   -2.68  7.0e-4   0.04  -2.78  -2.71  -2.68  -2.66   -2.6   4000    1.0
log\_lik[2,3]   -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[3,3]   -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[4,3]   -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[5,3]   -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[6,3]    -4.1  2.6e-3   0.17  -4.43  -4.21   -4.1  -3.99  -3.77   4000    1.0
log\_lik[7,3]   -4.77  3.5e-3   0.22  -5.21  -4.92  -4.77  -4.62  -4.34   4000    1.0
log\_lik[8,3]   -2.96  1.1e-3   0.07  -3.12   -3.0  -2.95  -2.91  -2.84   4000    1.0
log\_lik[9,3]   -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[10,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[11,3]  -2.69  6.9e-4   0.04  -2.78  -2.72  -2.69  -2.66  -2.61   4000    1.0
log\_lik[12,3]  -4.05  2.6e-3   0.17  -4.42  -4.14  -4.03  -3.93  -3.77   4000    1.0
log\_lik[13,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[14,3]  -3.77  2.3e-3   0.14  -4.09  -3.85  -3.75  -3.67  -3.53   4000    1.0
log\_lik[15,3]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[16,3]  -3.11  1.4e-3   0.09  -3.32  -3.16   -3.1  -3.05  -2.97   4000    1.0
log\_lik[17,3]  -4.36  3.0e-3   0.19  -4.79  -4.47  -4.34  -4.23  -4.03   4000    1.0
log\_lik[18,3]  -2.96  1.1e-3   0.07  -3.12   -3.0  -2.95  -2.91  -2.84   4000    1.0
log\_lik[19,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[20,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[21,3]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[22,3]  -3.56  1.9e-3   0.12  -3.79  -3.64  -3.56  -3.48  -3.32   4000    1.0
log\_lik[23,3]  -2.69  6.9e-4   0.04  -2.78  -2.72  -2.69  -2.66  -2.61   4000    1.0
log\_lik[24,3]  -3.34  1.6e-3    0.1  -3.53  -3.41  -3.34  -3.27  -3.13   4000    1.0
log\_lik[25,3]  -2.96  1.1e-3   0.07  -3.12   -3.0  -2.95  -2.91  -2.84   4000    1.0
log\_lik[26,3]  -3.56  1.9e-3   0.12  -3.79  -3.64  -3.56  -3.48  -3.32   4000    1.0
log\_lik[27,3]  -2.99  1.1e-3   0.07  -3.12  -3.03  -2.99  -2.94  -2.84   4000    1.0
log\_lik[28,3]  -3.34  1.6e-3    0.1  -3.53  -3.41  -3.34  -3.27  -3.13   4000    1.0
log\_lik[29,3]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[30,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[31,3]  -2.69  6.9e-4   0.04  -2.78  -2.72  -2.69  -2.66  -2.61   4000    1.0
log\_lik[32,3]   -3.3  1.6e-3    0.1  -3.54  -3.36  -3.29  -3.23  -3.13   4000    1.0
log\_lik[33,3]  -2.96  1.1e-3   0.07  -3.12   -3.0  -2.95  -2.91  -2.84   4000    1.0
log\_lik[34,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[35,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[36,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[37,3]  -5.15  4.0e-3   0.25  -5.66  -5.32  -5.14  -4.98  -4.67   4000    1.0
log\_lik[38,3]  -3.77  2.3e-3   0.14  -4.09  -3.85  -3.75  -3.67  -3.53   4000    1.0
log\_lik[39,3]  -2.84  9.6e-4   0.06  -2.97  -2.87  -2.83  -2.79  -2.73   4000    1.0
log\_lik[40,3]  -3.11  1.4e-3   0.09  -3.32  -3.16   -3.1  -3.05  -2.97   4000    1.0
log\_lik[41,3]  -2.96  1.1e-3   0.07  -3.12   -3.0  -2.95  -2.91  -2.84   4000    1.0
log\_lik[42,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[43,3]  -4.77  3.5e-3   0.22  -5.21  -4.92  -4.77  -4.62  -4.34   4000    1.0
log\_lik[44,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[45,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[46,3]  -2.74  8.1e-4   0.05  -2.85  -2.78  -2.74  -2.71  -2.65   4000    1.0
log\_lik[47,3]  -2.84  9.6e-4   0.06  -2.97  -2.87  -2.83  -2.79  -2.73   4000    1.0
log\_lik[48,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[49,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[50,3]   -3.3  1.6e-3    0.1  -3.54  -3.36  -3.29  -3.23  -3.13   4000    1.0
log\_lik[51,3]  -2.69  6.9e-4   0.04  -2.78  -2.72  -2.69  -2.66  -2.61   4000    1.0
log\_lik[52,3]   -3.3  1.6e-3    0.1  -3.54  -3.36  -3.29  -3.23  -3.13   4000    1.0
log\_lik[53,3]  -3.77  2.3e-3   0.14  -4.09  -3.85  -3.75  -3.67  -3.53   4000    1.0
log\_lik[54,3]  -2.84  9.6e-4   0.06  -2.97  -2.87  -2.83  -2.79  -2.73   4000    1.0
log\_lik[55,3]   -4.7  3.5e-3   0.22  -5.19  -4.83  -4.68  -4.55  -4.32   4000    1.0
log\_lik[56,3]   -3.3  1.6e-3    0.1  -3.54  -3.36  -3.29  -3.23  -3.13   4000    1.0
log\_lik[57,3]  -3.34  1.6e-3    0.1  -3.53  -3.41  -3.34  -3.27  -3.13   4000    1.0
log\_lik[58,3]   -4.1  2.6e-3   0.17  -4.43  -4.21   -4.1  -3.99  -3.77   4000    1.0
log\_lik[59,3]  -3.56  1.9e-3   0.12  -3.79  -3.64  -3.56  -3.48  -3.32   4000    1.0
log\_lik[60,3]  -3.56  1.9e-3   0.12  -3.79  -3.64  -3.56  -3.48  -3.32   4000    1.0
log\_lik[61,3]  -2.84  9.6e-4   0.06  -2.97  -2.87  -2.83  -2.79  -2.73   4000    1.0
log\_lik[62,3]  -2.76  8.0e-4   0.05  -2.86  -2.79  -2.76  -2.73  -2.66   4000    1.0
log\_lik[63,3]  -2.66  6.4e-4   0.04  -2.74  -2.69  -2.66  -2.63  -2.58   4000    1.0
log\_lik[64,3]  -3.56  1.9e-3   0.12  -3.79  -3.64  -3.56  -3.48  -3.32   4000    1.0
log\_lik[65,3]  -3.77  2.3e-3   0.14  -4.09  -3.85  -3.75  -3.67  -3.53   4000    1.0
log\_lik[66,3]  -3.56  1.9e-3   0.12  -3.79  -3.64  -3.56  -3.48  -3.32   4000    1.0
log\_lik[0,4]   -5.39  4.1e-3   0.26  -5.92  -5.56  -5.38  -5.22  -4.89   4000    1.0
log\_lik[1,4]   -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[2,4]   -3.98  2.4e-3   0.15  -4.28  -4.07  -3.97  -3.88   -3.7   4000    1.0
log\_lik[3,4]   -2.68  6.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[4,4]   -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[5,4]   -3.19  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[6,4]   -3.19  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[7,4]   -3.88  2.3e-3   0.14  -4.18  -3.97  -3.87  -3.78  -3.61   4000    1.0
log\_lik[8,4]   -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[9,4]   -2.88  9.5e-4   0.06  -3.01  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[10,4]  -2.66  6.5e-4   0.04  -2.75  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[11,4]  -4.29  2.7e-3   0.17  -4.64  -4.39  -4.28  -4.17  -3.96   4000    1.0
log\_lik[12,4]  -2.81  8.6e-4   0.05  -2.92  -2.85  -2.81  -2.77  -2.71   4000    1.0
log\_lik[13,4]  -3.26  1.4e-3   0.09  -3.44  -3.31  -3.25   -3.2  -3.08   4000    1.0
log\_lik[14,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[15,4]  -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[16,4]  -3.19  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[17,4]  -3.19  1.4e-3   0.09  -3.37  -3.24  -3.18  -3.13  -3.03   4000    1.0
log\_lik[18,4]  -5.24  4.0e-3   0.25  -5.76   -5.4  -5.23  -5.06  -4.77   4000    1.0
log\_lik[19,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[20,4]  -2.68  6.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[21,4]  -2.66  6.5e-4   0.04  -2.75  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[22,4]  -2.81  8.6e-4   0.05  -2.92  -2.85  -2.81  -2.77  -2.71   4000    1.0
log\_lik[23,4]  -2.73  7.5e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.64   4000    1.0
log\_lik[24,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[25,4]  -2.68  6.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[26,4]  -4.62  3.2e-3    0.2  -5.04  -4.75  -4.61  -4.49  -4.24   4000    1.0
log\_lik[27,4]  -3.71  2.0e-3   0.13  -3.97  -3.79   -3.7  -3.62  -3.47   4000    1.0
log\_lik[28,4]  -3.08  1.2e-3   0.08  -3.24  -3.12  -3.07  -3.03  -2.93   4000    1.0
log\_lik[29,4]  -2.66  6.5e-4   0.04  -2.75  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[30,4]  -3.61  1.9e-3   0.12  -3.87  -3.69  -3.61  -3.53  -3.39   4000    1.0
log\_lik[31,4]  -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[32,4]  -2.88  9.5e-4   0.06  -3.01  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[33,4]  -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[34,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[35,4]  -4.29  2.7e-3   0.17  -4.64  -4.39  -4.28  -4.17  -3.96   4000    1.0
log\_lik[36,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[37,4]  -2.68  6.7e-4   0.04  -2.76   -2.7  -2.67  -2.65   -2.6   4000    1.0
log\_lik[38,4]  -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[39,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[40,4]  -2.88  9.5e-4   0.06  -3.01  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[41,4]  -3.71  2.0e-3   0.13  -3.97  -3.79   -3.7  -3.62  -3.47   4000    1.0
log\_lik[42,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[43,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[44,4]  -3.26  1.4e-3   0.09  -3.44  -3.31  -3.25   -3.2  -3.08   4000    1.0
log\_lik[45,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[46,4]  -3.61  1.9e-3   0.12  -3.87  -3.69  -3.61  -3.53  -3.39   4000    1.0
log\_lik[47,4]  -2.88  9.5e-4   0.06  -3.01  -2.92  -2.88  -2.84  -2.77   4000    1.0
log\_lik[48,4]  -3.61  1.9e-3   0.12  -3.87  -3.69  -3.61  -3.53  -3.39   4000    1.0
log\_lik[49,4]  -3.71  2.0e-3   0.13  -3.97  -3.79   -3.7  -3.62  -3.47   4000    1.0
log\_lik[50,4]  -2.66  6.5e-4   0.04  -2.75  -2.69  -2.66  -2.64  -2.59   4000    1.0
log\_lik[51,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[52,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[53,4]  -3.71  2.0e-3   0.13  -3.97  -3.79   -3.7  -3.62  -3.47   4000    1.0
log\_lik[54,4]  -2.65  6.4e-4   0.04  -2.73  -2.68  -2.65  -2.63  -2.58   4000    1.0
log\_lik[55,4]  -2.81  8.6e-4   0.05  -2.92  -2.85  -2.81  -2.77  -2.71   4000    1.0
log\_lik[56,4]  -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[57,4]  -2.73  7.5e-4   0.05  -2.83  -2.76  -2.73   -2.7  -2.64   4000    1.0
log\_lik[58,4]  -3.26  1.4e-3   0.09  -3.44  -3.31  -3.25   -3.2  -3.08   4000    1.0
log\_lik[59,4]  -2.93  1.0e-3   0.06  -3.06  -2.97  -2.93  -2.89  -2.81   4000    1.0
log\_lik[60,4]  -2.78  8.1e-4   0.05  -2.89  -2.81  -2.78  -2.74  -2.68   4000    1.0
log\_lik[61,4]  -4.85  3.5e-3   0.22  -5.31  -4.99  -4.84   -4.7  -4.44   4000    1.0
log\_lik[62,4]  -3.38  1.6e-3    0.1   -3.6  -3.45  -3.38  -3.32   -3.2   4000    1.0
log\_lik[63,4]  -3.61  1.9e-3   0.12  -3.87  -3.69  -3.61  -3.53  -3.39   4000    1.0
log\_lik[64,4]  -2.71  7.1e-4   0.04   -2.8  -2.73   -2.7  -2.67  -2.62   4000    1.0
log\_lik[65,4]  -2.81  8.6e-4   0.05  -2.92  -2.85  -2.81  -2.77  -2.71   4000    1.0
log\_lik[66,4]  -3.47  1.7e-3   0.11  -3.69  -3.53  -3.46   -3.4  -3.26   4000    1.0
ypred[0]       14.08    0.09   5.72   2.95   10.2  14.09  17.87  25.31   4000    1.0
ypred[1]       14.35    0.09   5.68   3.07  10.52  14.26   18.2  25.59   4000    1.0
ypred[2]       13.98    0.09   5.56   3.09  10.25  14.05  17.71  24.85   4000    1.0
ypred[3]       14.53    0.09   5.68   3.53  10.78  14.53  18.29  26.03   3793    1.0
ypred[4]       14.14    0.09   5.65   3.05   10.4  14.09  17.95  25.14   4000    1.0
mu\_new         14.17    0.02    0.9  12.32  13.81   14.2  14.57  15.88   2677    1.0
ypred\_new      14.21    0.09   5.69   3.31  10.31  14.05  18.16  25.14   4000    1.0
lp\_\_          -754.5    0.07   2.37 -759.8 -756.0 -754.2 -752.8 -750.6   1260    1.0

Samples were drawn using NUTS at Sun Dec  9 13:49:18 2018.
For each parameter, n\_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).


    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
